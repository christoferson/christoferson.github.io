<!DOCTYPE html>
<html lang="en-US">
<head>
	<meta charset="utf-8">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	
	<!-- Open Graph / Facebook -->
	<meta property="og:type" content="website">
	<meta property="og:locale" content="en_US">
	<meta property="og:url" content="https://christoferson.github.io/">
	<meta property="og:site_name" content="christoferson.github.io">
	<meta property="og:title" content="Meta Tags Preview, Edit and Generate">
	<meta property="og:description" content="Christoferson Chua GitHub Page">

	<!-- Twitter -->
	<meta property="twitter:card" content="summary_large_image">
	<meta property="twitter:url" content="https://christoferson.github.io/">
	<meta property="twitter:title" content="christoferson.github.io">
	<meta property="twitter:description" content="Christoferson Chua GitHub Page">
	
	<script type="application/ld+json">{
		"name": "christoferson.github.io",
		"description": "Machine Learning",
		"url": "https://christoferson.github.io/",
		"@type": "WebSite",
		"headline": "christoferson.github.io",
		"@context": "https://schema.org"
	}</script>
	
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet" />
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js"></script>
  
	<title>Christoferson Chua</title>
	<meta name="title" content="Christoferson Chua | GitHub Page | Machine Learning">
	<meta name="description" content="Christoferson Chua GitHub Page - Machine Learning">
	<meta name="keywords" content="Backend,Java,Spring,Aws,Python,Machine Learning">
	
	<link rel="stylesheet" href="style.css">
	
</head>
<body>

<div class="container-fluid p-5 bg-primary text-white text-center">
  <h1>SageMaker</h1>
  
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Object Detection</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<div class="row">
		<div class="col-sm-12">
            <p style="color:blue;">Single Shot MultiBox Detector</p>
            <p>
                A Single Shot MultiBox Detector (SSD) is a type of object detection algorithm used in computer vision and deep learning. It is a popular and efficient method for detecting multiple objects within an image in a single forward pass of the neural network.
            </p>
            <p>Features</p>
            <ul>
                <li>Single-Stage Detector: Unlike two-stage detectors like R-CNN, which first generate region proposals and then classify them, SSD performs object detection in a single stage, making it faster and more efficient.</li>
                <li>Multi-Scale Feature Maps: SSD uses feature maps from multiple layers of the CNN to detect objects of different scales. This allows it to detect both small and large objects effectively.</li>
            </ul>
            <p>Main Components</p>
            <ul>
                <li>Base Network: This is typically a pre-trained CNN like VGG or ResNet, which is used to extract feature maps from the input image.
                </li>
                <li>Multibox Convolutional Layers: These are additional convolutional layers added on top of the base network. They are responsible for predicting the offsets and confidences for the default bounding boxes at each location in the feature maps.</li>
            </ul>
            <p>
                SSD strikes a balance between accuracy and speed, making it suitable for real-time object detection applications, such as object tracking, autonomous driving, and robotics. It has been widely adopted and extended by researchers and practitioners due to its simplicity and effectiveness.
            </p>
		</div>
	</div>
    <br/>
	<div class="row">
		<div class="col-sm-12">
        <p style="color:blue;">VGG (Visual Geometry Group)</p>
        <p>
            The VGG architecture was introduced by researchers from the Visual Geometry Group at the University of Oxford in 2014. It is characterized by its simplicity and the use of small convolutional filters (3x3) with a deep stack of convolutional layers. The VGG network consists of 16 or 19 layers, depending on the variant (VGG-16 or VGG-19).
        </p>
        <p>The main advantage of the VGG architecture is its uniform and straightforward design, which makes it easy to understand and implement. However, as the network gets deeper, the number of parameters increases significantly, leading to higher computational costs and the risk of overfitting.</p>
		</div>
	</div>
    <br/>
	<div class="row">
		<div class="col-sm-12">
        <p style="color:blue;">ResNet (Residual Network)</p>
        <p>
            ResNet was introduced by researchers from Microsoft Research in 2015. It addresses the vanishing gradient problem encountered in very deep neural networks by introducing residual connections or skip connections. These connections allow the gradients to flow more easily through the network, enabling the training of much deeper architectures.
        </p>
		</div>
	</div>

</div>



<div class="container mt-5">
	<h3 class="text-primary h4">Image Classification</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<div class="row">
		<div class="col-sm-12">
            <p style="color:blue;">ImageNet</p>
            <p>
            </p>
		</div>
	</div>
    <br/>
	<div class="row">
		<div class="col-sm-12">
        <p style="color:blue;">RESNET</p>
        <p>
        
        </p>
		</div>
	</div>
    <br/>

</div>



<div class="container mt-5">
	<h3 class="text-primary h4">Semantic Segmentation</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
    <p>Not the same as Image Classification and Object Detection Algorithm</p>
	<div class="row">
		<div class="col-sm-12">
            <p style="color:blue;">MxNet Gluon Framework Gluon CVToolkit</p>
            <p>
            </p>
            <ul>
                <li>Fully Convolutional Network</li>
                <li>Pyramid Scene Parsing</li>
                <li>DeepLabV3</li>
            </ul>
            <ul>
                <li>Encoder (backbone)</li>
                <li>Decoder constructs segmentation mask</li>
            </ul>
		</div>
	</div>
    
    <br/>

</div>

<div class="container mt-5">
	<h3 class="text-primary h4">Linear Learner</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
    <p>Not the same as Image Classification and Object Detection Algorithm</p>
	<div class="row">
		<div class="col-sm-12">
            <p style="color:blue;">MxNet Gluon Framework Gluon CVToolkit</p>
            <p>
            </p>
            <ul>
                <li>Fully Convolutional Network</li>
                <li>Pyramid Scene Parsing</li>
                <li>DeepLabV3</li>
            </ul>
            <ul>
                <li>Encoder (backbone)</li>
                <li>Decoder constructs segmentation mask</li>
            </ul>
		</div>
	</div>
    
    <br/>

</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Forecasting</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
    <p></p>
	<div class="row">
		<div class="col-sm-12">
            <p style="color:blue;">DeepAR</p>
            <p>A supervised learning algorithm for forecasting scalar (one-dimensional) time series using recurrent neural networks (RNN). 
            </p>
            <ul>
                <li>Purpose: designed for producing accurate probabilistic forecasts for time series data.</li>
                <li>Cold-start Problems: It can handle "cold-start" forecasting on time series with little or no history.</li>
                <li>Seasonal Patterns: The algorithm can learn complex seasonal patterns and relationships between different time series.</li>
				<li>Probabilistic Forecasting: Instead of point estimates, DeepAR provides probabilistic forecasts, giving you a range of possible outcomes and their likelihoods.</li>
				<li>Automatic Feature Engineering: It automatically creates feature sets based on time series data, reducing the need for manual feature engineering.</li>
				<li>Handling Missing Values: DeepAR can deal with missing values in the input data.</li>
				<li>Scalability: It's designed to handle a large number of time series efficiently.</li>
				<li>Applications: It's useful in various domains like retail demand forecasting, server load prediction, financial forecasting, and more.</li>
            </ul>
            <p>DeepAR is particularly useful when you have many time series and want to train a single model for all of them, especially when some time series have little historical data. It's a powerful tool for businesses and researchers dealing with time-dependent data and needing accurate forecasts.</p>
			<p style="color:rgb(8, 138, 99);">Multiple Time Series Explained</p>
			<p>Example: Retail Store Chain Sales Forecasting</p>
			<ul>
				<li>Imagine you're a data scientist working for a large retail chain with 100 stores across the country. Your task is to forecast daily sales for each store for the next 30 days. </li>
				<li>Single Time Series Approach: You could create 100 separate models, one for each store, using only that store's historical sales data.</li>
				<li>Multiple Time Series Approach with DeepAR: Instead, you can use DeepAR to create a single model trained on data from all 100 stores simultaneously.</li>
			</ul>
			<p>Process</p>
			<ul>
				<li>Input Data: You provide DeepAR with historical daily sales data for all 100 stores.</li>
				<li>Training: DeepAR trains a single model using all this data. It learns patterns that are common across stores as well as store-specific patterns.</li>
				<li>Features: You can include store-specific features (like location, size, etc.) and global features (like national holidays, weather, etc.) that affect all stores.</li>
				<li>Output: The trained model can then generate forecasts for all 100 stores.</li>
			</ul>
			<p>Benefits</p>
			<ul>
				<li>Improved Accuracy: The model can leverage patterns learned from all stores, which is especially helpful for stores with limited historical data.</li>
				<li>Handling New Stores: If you open a new store, you can still generate a forecast for it based on patterns learned from other stores, even without historical data for the new store.</li>
				<li>Efficiency: You manage and train one model instead of 100 separate models.</li>
				<li>Shared Learning: The model can capture effects that are common across stores (like seasonal patterns or the impact of holidays) more effectively.</li>
			</ul>
			<p>
				This multi-time series capability makes DeepAR particularly powerful for businesses dealing with numerous related time series, like retail chains, energy companies forecasting consumption across multiple locations, or financial institutions predicting various economic indicators.
			</p>
			<ul>
				<li>Amazon Forecast: Another AWS service that automatically tests multiple algorithms (including DeepAR) and selects the best one for your data.
				</li>
				<li>ARIMA (AutoRegressive Integrated Moving Average): A classical statistical method for time series forecasting.</li>
				<li>SARIMA (Seasonal ARIMA): An extension of ARIMA that supports seasonal data.</li>
				<li>Exponential Smoothing Methods: Including Simple Exponential Smoothing, Holt's Linear Trend Method, and Holt-Winters' Seasonal Method.</li>
				<li>LSTM (Long Short-Term Memory): A type of recurrent neural network often used for sequence prediction problems.</li>
			</ul>
		</div>
	</div>
</div>
    
<br/>


<div class="container mt-5">
	<h3 class="text-primary h4">Blazing Text</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
			<p style="color:blue;">Word2Vec</p>
			<p>Word2Vec is a popular technique in natural language processing (NLP) for creating word embeddings. 
				Word2Vec transforms words into dense vector representations in a high-dimensional space, where semantically similar words are positioned closer to each other. 
			</p>
			Key Aspects
			<ul>
				<li>It learns vector representations of words from large text corpora.</li>
				<li>It captures semantic and syntactic relationships between words.</li>
				<li>It allows for mathematical operations on words, enabling analogy solving.</li>
			</ul>
			Main Architectures
			<ul>
				<li>Continuous Bag of Words (CBOW): Predicts a target word from its context words.</li>
				<li>Skip-gram: Predicts context words given a target word.</li>
			</ul>
			Examples
			<ul>
				<li>Word Similarity: Word2Vec can find words with similar meanings. For instance:
					<ul>
						<li>"king" might be close to "queen," "monarch," and "ruler"</li>
						<li>"car" might be close to "vehicle," "automobile," and "truck"</li>
					</ul>
				</li>
				<li>Analogy Solving: Word2Vec can solve analogies like "king is to queen as man is to woman": 
					<br/>vector("king") - vector("man") + vector("woman") ≈ vector("queen")</li>
				<li>Clustering: Words with similar meanings cluster together in the vector space:
					<ul>
						<li>Fruits: apple, banana, orange, pear</li>
						<li>Countries: France, Germany, Italy, Spain</li>
					</ul>
				</li>
				<li>Semantic Relationships: Word2Vec captures various semantic relationships:
					<ul>
						<li>Capital-Country: Paris-France, Berlin-Germany</li>
						<li>Verb tenses: walk-walked, run-ran</li>
					</ul>
				</li>
				<li>Syntactic Relationships: It also captures syntactic relationships:
					<ul>
					<li>Adjective-Adverb: quick-quickly, happy-happily</li>
					<li>Singular-Plural: cat-cats, dog-dogs</li>
					</ul>
				</ul>
				</li>
				<li>Domain-Specific Relationships: In a medical corpus:
					<br/>
					"aspirin" might be close to "painkiller," "ibuprofen," and "medication"</li>
				<li>Cross-lingual Word Embeddings: When trained on multilingual corpora:
					"dog" (English) might be close to "perro" (Spanish) and "chien" (French)</li>
			</ul>
			Applications
			<ul>
				<li>Information Retrieval: Improving search results by understanding query intent.</li>
				<li>Machine Translation: Enhancing translation quality by capturing word meanings.</li>
				<li>Sentiment Analysis: Understanding the sentiment of words in context.</li>
				<li>Named Entity Recognition: Identifying and classifying named entities in text.</li>
				<li>Recommendation Systems: Suggesting similar items based on textual descriptions.</li>
			</ul>
		</div>

		<div class="col-sm-12">
			<p style="color:blue;">Text Classification</p>
			<p>Text classification is a fundamental task in natural language processing (NLP) where the goal is to automatically categorize text documents into predefined categories or classes. It's widely used in various applications, from spam detection to sentiment analysis.
			</p>
			<ul>
				<li>Purpose: designed for producing accurate probabilistic forecasts for time series data.</li>
				<li>Types of Text Classification: a) Binary Classification: Two classes (e.g., spam vs. not spam) b) Multi-class Classification: More than two mutually exclusive classes c) Multi-label Classification: One document can belong to multiple classes
				</li>
			</ul>
			Techniques and Algorithms:
			<ul>
				<li>
					Traditional Machine Learning:
					<ul>
						<li>Naive Bayes: Probabilistic classifier based on Bayes' theorem</li>
						<li>Support Vector Machines (SVM): Finds the hyperplane that best separates classes</li>
						<li>Decision Trees and Random Forests: Tree-based models</li>
					</ul>
					Deep Learning:
					<ul>
						<li>Convolutional Neural Networks (CNN): Effective for capturing local patterns</li>
						<li>Recurrent Neural Networks (RNN) / Long Short-Term Memory (LSTM): Good for sequential data</li>
						<li>Transformer-based models: BERT, GPT, etc., which have achieved state-of-the-art results</li>
					</ul>
				</li>
			</ul>
			Challenges in Text Classification:
			<ul>
				<li>Imbalanced datasets</li>
				<li>Handling long documents</li>
				<li>Dealing with multi-label classification</li>
				<li>Domain-specific vocabulary and context</li>
				<li>Handling multiple languages</li>
			</ul>
			Applications:
			<ul>
				<li>Spam Detection: Classifying emails as spam or not spam</li>
				<li>Sentiment Analysis: Determining the sentiment of reviews or social media posts</li>
				<li>Topic Categorization: Assigning news articles to categories</li>
				<li>Intent Classification: In chatbots and virtual assistants</li>
				<li>Content Moderation: Identifying inappropriate or offensive content</li>
			</ul>
			Evaluation Metrics:
			<ul>
				<li>Accuracy: Overall correctness</li>
				<li>Precision: Exactness of positive predictions</li>
				<li>Recall: Completeness of positive predictions</li>
				<li>F1-score: Harmonic mean of precision and recall</li>
				<li>Confusion Matrix: Detailed breakdown of correct and incorrect classifications</li>
			</ul>
			Tools and Libraries
			<uL>
				<li>Scikit-learn: For traditional ML algorithms</li>
				<li>TensorFlow and PyTorch: For deep learning models</li>
				<li>Hugging Face Transformers: For state-of-the-art NLP models</li>
				<li>NLTK and spaCy: For text preprocessing and feature extraction</li>
			</uL>
			
		</div>
	</div>
</div>
		
<br/>



<div class="container mt-5">
	<h3 class="text-primary h4">Random Cut Forest</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p>
		An unsupervised machine learning algorithm primarily used for anomaly detection and data analysis. It was developed by Amazon and is particularly effective for detecting anomalies in high-dimensional datasets and streaming data. RCF is an ensemble learning method that combines multiple decision trees (called "random cut trees") to identify unusual or rare instances within a dataset.
	</p>
	<p>A Random Cut Forest is a collection of random cut trees. Each random cut tree is constructed by recursively partitioning the input space using randomly selected dimensions and split points. The structure of these trees captures the density and distribution of the data points, allowing the algorithm to identify anomalies effectively.</p>
	<p>
		Random Cut Forest is a powerful and versatile algorithm for anomaly detection, particularly suited for high-dimensional and streaming data scenarios. Its ability to adapt to changing data distributions and efficient processing make it a valuable tool in many real-world applications where detecting unusual patterns is crucial.
	</p>
	<div class="row">
		<div class="col-sm-12">
			<p style="color:blue;">Test</p>
			
			<p style="color:rgb(8, 138, 99);">Multiple Time Series Explained</p>
			Key Concepts:
			<ul>
				<li>Random Cut Tree: A binary tree where each non-leaf node represents a cut in the data space along a randomly chosen dimension.</li>
				<li>Anomaly Score: A measure of how anomalous a data point is, based on the average path length to that point across all trees in the forest.</li>
				<li>Sampling: RCF often uses sampling techniques to handle large datasets efficiently.</li>
			</ul>
			Uses:
			<ul>
				<li>Anomaly Detection: The primary application of RCF is identifying unusual patterns or outliers in data.</li>
				<li>Data Quality Monitoring: Detecting data quality issues or inconsistencies in streaming data.</li>
				<li>Fraud Detection: Identifying suspicious activities or transactions in financial systems.</li>
				<li>System Health Monitoring: Detecting unusual behavior in IT systems or IoT devices.</li>
				<li>Time Series Analysis: Identifying anomalies in time series data, such as unexpected spikes or dips.</li>
			</ul>
			Uses:
			<ul>
				<li>Cloud infrastructure monitoring</li>
				<li>Financial fraud detection</li>
				<li>Industrial equipment failure prediction</li>
				<li>Network intrusion detection</li>
				<li>E-commerce anomaly detection (e.g., unusual shopping patterns)</li>
			</ul>
		</div>
	</div>
	
	<br/>
	
</div>




<!-- Template -->

<div class="container mt-5">
	<h3 class="text-primary h4">Template</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
			<p style="color:blue;">Test</p>
			
			<p style="color:rgb(8, 138, 99);">Multiple Time Series Explained</p>
			
		</div>
	</div>
	
	<br/>
	
</div>

<!-- Template -->

		
</div>

<br/>
<br/>
<footer class="_fixed-bottom">
<div class="container-fluid p-2 bg-primary text-white text-center">
  <h6>christoferson.github.io 2023</h6>
  <!--<div style="font-size:8px;text-decoration:italic;">about</div>-->
</div>
</footer>

</body>
</html>
