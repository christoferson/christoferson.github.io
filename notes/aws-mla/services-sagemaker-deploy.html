<!DOCTYPE html>
<html lang="en-US">
<head>
	<meta charset="utf-8">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	
	<!-- Open Graph / Facebook -->
	<meta property="og:type" content="website">
	<meta property="og:locale" content="en_US">
	<meta property="og:url" content="https://christoferson.github.io/">
	<meta property="og:site_name" content="christoferson.github.io">
	<meta property="og:title" content="Meta Tags Preview, Edit and Generate">
	<meta property="og:description" content="Christoferson Chua GitHub Page">

	<!-- Twitter -->
	<meta property="twitter:card" content="summary_large_image">
	<meta property="twitter:url" content="https://christoferson.github.io/">
	<meta property="twitter:title" content="christoferson.github.io">
	<meta property="twitter:description" content="Christoferson Chua GitHub Page">
	
	<script type="application/ld+json">{
		"name": "christoferson.github.io",
		"description": "Machine Learning",
		"url": "https://christoferson.github.io/",
		"@type": "WebSite",
		"headline": "christoferson.github.io",
		"@context": "https://schema.org"
	}</script>

    
	
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet" />
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js"></script>
  
	<title>Christoferson Chua</title>
	<meta name="title" content="Christoferson Chua | GitHub Page | Machine Learning">
	<meta name="description" content="Christoferson Chua GitHub Page - Machine Learning">
	<meta name="keywords" content="Backend,Java,Spring,Aws,Python,Machine Learning">
	
	<link rel="stylesheet" href="style.css">
	
    <style>
        details {
            border: 1px solid #aaa;
            border-radius: 2px;
            padding: .5em .5em 0;
            color: indigo;
            font-size: 12px;
        }
    
        summary {
            font-weight: bold;
            margin: -.5em -.5em 0;
            padding: .5em;
            cursor: pointer;
        }
    
        details[open] {
            padding: .5em;
        }
    
        details[open] summary {
            border-bottom: 1px solid #aaa;
            margin-bottom: .5em;
        }
    </style>

</head>
<body>

<div class="container-fluid p-5 bg-primary text-white text-center">
  <h1>Machine Learning Engineer Associate (MLA) - Services SageMaker - Deploy</h1>  
</div>



<div style="color: darkmagenta;font-size: 20px;padding:5px;">Model Deploy</div>
<hr style="height: 12px;background-color:#0066cc"/>





<div class="container mt-5">
	<h3 class="text-primary h4">Deploy models for inference</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">

		<div class="col-sm-12">
            
            <p style="color: #333; font-size: 16px;">Deploy models for inference with Amazon SageMaker</p> <p style="color: #555; font-size: 14px;">Amazon SageMaker offers a wide range of ML infrastructure and model deployment options to meet various inference needs. SageMaker Inference helps you:</p> <ul> <li>Scale your model deployment</li> <li>Manage models effectively in production</li> <li>Reduce operational burden</li> </ul> <p style="color: #555; font-size: 14px;">SageMaker provides several inference options:</p> <ul> <li>Real-time endpoints for low latency inference</li> <li>Serverless endpoints for fully managed infrastructure and auto-scaling</li> <li>Asynchronous endpoints for batches of requests</li> </ul> <p style="color: #333; font-size: 16px;">Choosing a feature</p> <p style="color: #555; font-size: 14px;">SageMaker offers different features for various use cases:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Use Case</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Feature</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">1. Low-code or no-code environment</td> <td style="border: 1px solid #ddd; padding: 8px;">Amazon SageMaker JumpStart</td> <td style="border: 1px solid #ddd; padding: 8px;">Deploy pre-trained models through Amazon SageMaker Studio interface</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">2. Code-based deployment with flexibility</td> <td style="border: 1px solid #ddd; padding: 8px;">ModelBuilder class in SageMaker Python SDK</td> <td style="border: 1px solid #ddd; padding: 8px;">Deploy custom models with fine-grained control over settings</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">3. Large-scale deployment</td> <td style="border: 1px solid #ddd; padding: 8px;">AWS SDK for Python (Boto3) and AWS CloudFormation</td> <td style="border: 1px solid #ddd; padding: 8px;">Manage models at scale in production with IaC and CI/CD tools</td> </tr> </table> <p style="color: #333; font-size: 16px;">Feature Comparison</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Low-code</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Code-based deployment</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Large-scale deployment</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Optimized for</strong></td> <td style="border: 1px solid #ddd; padding: 8px;">Fast deployments of popular open source models</td> <td style="border: 1px solid #ddd; padding: 8px;">Deploying your own models</td> <td style="border: 1px solid #ddd; padding: 8px;">Ongoing management of models in production</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Considerations</strong></td> <td style="border: 1px solid #ddd; padding: 8px;">Limited customization for container settings</td> <td style="border: 1px solid #ddd; padding: 8px;">Requires Python coding skills</td> <td style="border: 1px solid #ddd; padding: 8px;">Requires infrastructure management and AWS SDK knowledge</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Recommended environment</strong></td> <td style="border: 1px solid #ddd; padding: 8px;">SageMaker domain</td> <td style="border: 1px solid #ddd; padding: 8px;">Python development environment or SageMaker IDE</td> <td style="border: 1px solid #ddd; padding: 8px;">AWS CLI, local development environment, IaC and CI/CD tools</td> </tr> </table> <p style="color: #333; font-size: 16px;">Additional Deployment Options</p> <p style="color: #555; font-size: 14px;">SageMaker offers various inference options:</p> <ul> <li>Real-time inference: For interactive, low latency requirements</li> <li>Serverless Inference: Deploy models without managing infrastructure</li> <li>Asynchronous inference: For large payloads and long processing times</li> </ul> <p style="color: #333; font-size: 16px;">Cost Optimization</p> <p style="color: #555; font-size: 14px;">To optimize inference costs, consider:</p> <ul> <li>SageMaker Neo: Optimize model performance and efficiency</li> <li>Autoscaling: Dynamically adjust compute resources based on traffic patterns</li> </ul>

            <hr />

            <p style="color: #333; font-size: 16px;">Detailed Comparison of Amazon SageMaker Endpoint Types</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Feature</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Real-time Inference</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Serverless Inference</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Asynchronous Inference</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Use Case</td> <td style="border: 1px solid #ddd; padding: 8px;">Low-latency, interactive applications</td> <td style="border: 1px solid #ddd; padding: 8px;">Intermittent or unpredictable workloads</td> <td style="border: 1px solid #ddd; padding: 8px;">Large payloads, long processing times</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Latency</td> <td style="border: 1px solid #ddd; padding: 8px;">Lowest (milliseconds)</td> <td style="border: 1px solid #ddd; padding: 8px;">Low (seconds, with potential cold starts)</td> <td style="border: 1px solid #ddd; padding: 8px;">Highest (minutes to hours)</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Scalability</td> <td style="border: 1px solid #ddd; padding: 8px;">Manual or auto-scaling</td> <td style="border: 1px solid #ddd; padding: 8px;">Automatic scaling</td> <td style="border: 1px solid #ddd; padding: 8px;">Automatic scaling</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Cost Model</td> <td style="border: 1px solid #ddd; padding: 8px;">Pay for provisioned instances</td> <td style="border: 1px solid #ddd; padding: 8px;">Pay per request and compute time</td> <td style="border: 1px solid #ddd; padding: 8px;">Pay for processing time</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Max. Payload Size</td> <td style="border: 1px solid #ddd; padding: 8px;">6 MB</td> <td style="border: 1px solid #ddd; padding: 8px;">6 MB</td> <td style="border: 1px solid #ddd; padding: 8px;">1 GB</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Max. Processing Time</td> <td style="border: 1px solid #ddd; padding: 8px;">60 seconds</td> <td style="border: 1px solid #ddd; padding: 8px;">60 seconds</td> <td style="border: 1px solid #ddd; padding: 8px;">1 hour</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Infrastructure Management</td> <td style="border: 1px solid #ddd; padding: 8px;">User managed</td> <td style="border: 1px solid #ddd; padding: 8px;">Fully managed</td> <td style="border: 1px solid #ddd; padding: 8px;">Fully managed</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Cold Starts</td> <td style="border: 1px solid #ddd; padding: 8px;">No</td> <td style="border: 1px solid #ddd; padding: 8px;">Yes (mitigated by provisioned concurrency)</td> <td style="border: 1px solid #ddd; padding: 8px;">No</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Advantages</td> <td style="border: 1px solid #ddd; padding: 8px;"> <ul> <li>Lowest latency</li> <li>Predictable performance</li> <li>Full control over instance types</li> </ul> </td> <td style="border: 1px solid #ddd; padding: 8px;"> <ul> <li>No infrastructure management</li> <li>Automatic scaling</li> <li>Cost-effective for variable workloads</li> </ul> </td> <td style="border: 1px solid #ddd; padding: 8px;"> <ul> <li>Handles large payloads</li> <li>Long processing times</li> <li>Cost-effective for batch processing</li> </ul> </td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Limitations</td> <td style="border: 1px solid #ddd; padding: 8px;"> <ul> <li>Requires capacity planning</li> <li>Potentially higher costs for idle resources</li> <li>Limited payload size and processing time</li> </ul> </td> <td style="border: 1px solid #ddd; padding: 8px;"> <ul> <li>Potential cold start latency</li> <li>Limited customization options</li> <li>Max. 6 MB payload and 60 seconds processing</li> </ul> </td> <td style="border: 1px solid #ddd; padding: 8px;"> <ul> <li>Not suitable for real-time applications</li> <li>Requires additional setup for result handling</li> <li>Max. 1 hour processing time</li> </ul> </td> </tr> </table> <p style="color: #555; font-size: 14px;">Key takeaways:</p> <ul> <li><strong>Real-time Inference</strong> is best for applications requiring immediate responses and consistent low latency, such as interactive web applications or real-time decision making systems.</li> <li><strong>Serverless Inference</strong> is ideal for applications with variable or unpredictable traffic patterns, offering automatic scaling and cost optimization for sporadic workloads.</li> <li><strong>Asynchronous Inference</strong> excels in scenarios involving large payloads or long processing times, such as batch processing of images or videos, or complex ML models that require extensive computation.</li> </ul> <p style="color: #555; font-size: 14px;">When choosing an endpoint type, consider factors such as latency requirements, payload size, processing time, traffic patterns, and cost optimization needs.
            
            <p style="color: #555; font-size: 14px;">Each type has its strengths and is designed to address specific use cases. Here are some additional considerations when choosing an endpoint type:</p> <ul> <li><strong>Traffic patterns:</strong> If your workload has consistent, predictable traffic, real-time endpoints might be more suitable. For sporadic or unpredictable traffic, serverless inference can be more cost-effective.</li> <li><strong>Model complexity:</strong> Complex models with long inference times might benefit from asynchronous inference, while simpler models with quick inference times are well-suited for real-time or serverless endpoints.</li> <li><strong>Integration requirements:</strong> Consider how the endpoint will integrate with your existing infrastructure and applications. Real-time endpoints offer the most flexibility in terms of integration options.</li> <li><strong>Budget constraints:</strong> Serverless and asynchronous inference can offer cost savings for certain workloads, but it's important to analyze your specific use case to determine the most cost-effective option.</li> </ul> <p style="color: #333; font-size: 16px;">Advanced Features and Optimizations</p> <p style="color: #555; font-size: 14px;">Amazon SageMaker offers several advanced features and optimizations that can be applied across different endpoint types:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Feature</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Applicable Endpoint Types</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Multi-Model Endpoints</td> <td style="border: 1px solid #ddd; padding: 8px;">Host multiple models on a single endpoint, reducing infrastructure costs and improving resource utilization.</td> <td style="border: 1px solid #ddd; padding: 8px;">Real-time, Serverless</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Auto Scaling</td> <td style="border: 1px solid #ddd; padding: 8px;">Automatically adjust the number of instances to match the workload demand.</td> <td style="border: 1px solid #ddd; padding: 8px;">Real-time</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Elastic Inference</td> <td style="border: 1px solid #ddd; padding: 8px;">Attach GPU-powered inference acceleration to a CPU-based instance for cost-effective inference.</td> <td style="border: 1px solid #ddd; padding: 8px;">Real-time</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">SageMaker Neo</td> <td style="border: 1px solid #ddd; padding: 8px;">Optimize machine learning models to run more efficiently on specific hardware platforms.</td> <td style="border: 1px solid #ddd; padding: 8px;">All</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Inference Pipeline</td> <td style="border: 1px solid #ddd; padding: 8px;">Create a pipeline of multiple models or preprocessing logic that are invoked sequentially on a single endpoint.</td> <td style="border: 1px solid #ddd; padding: 8px;">Real-time, Serverless</td> </tr> </table> <p style="color: #333; font-size: 16px;">Monitoring and Management</p> <p style="color: #555; font-size: 14px;">Regardless of the endpoint type chosen, it's crucial to implement proper monitoring and management practices:</p> <ul> <li><strong>Amazon CloudWatch:</strong> Use CloudWatch to monitor endpoint metrics such as invocations, latency, and errors.</li> <li><strong>Model Monitor:</strong> Implement SageMaker Model Monitor to detect concept drift and data quality issues in your deployed models.</li> <li><strong>A/B Testing:</strong> Utilize SageMaker's built-in A/B testing capabilities to compare different model versions or configurations.</li> <li><strong>Endpoint Deployment Guardrails:</strong> Implement deployment strategies like blue/green deployments to minimize risk when updating models in production.</li> </ul> <p style="color: #333; font-size: 16px;">Best Practices</p> <p style="color: #555; font-size: 14px;">To ensure optimal performance and cost-effectiveness of your SageMaker endpoints, consider the following best practices:</p> <ul> <li>Regularly review and optimize your endpoint configurations based on actual usage patterns.</li> <li>Use appropriate instance types that match your model's resource requirements.</li> <li>Implement proper error handling and retry mechanisms in your client applications.</li> <li>Leverage SageMaker's built-in security features, such as encryption at rest and in transit.</li> <li>Implement a robust CI/CD pipeline for model deployment and updates.</li> <li>Regularly update your SageMaker SDK and dependencies to benefit from the latest features and optimizations.</li> </ul> <p style="color: #555; font-size: 14px;">By carefully considering your use case requirements and leveraging SageMaker's various endpoint types and advanced features, you can create an efficient, scalable, and cost-effective inference solution for your machine learning models.</p>

            <hr />

            <p style="color: #333; font-size: 16px;">Deploy a Model in Amazon SageMaker</p> <p style="color: #555; font-size: 14px;">After training your machine learning model, Amazon SageMaker offers various deployment options for getting predictions. The choice depends on your specific use case:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Deployment Option</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Use Case</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">SageMaker real-time hosting services</td> <td style="border: 1px solid #ddd; padding: 8px;">Persistent, real-time endpoints for single predictions</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Serverless Inference</td> <td style="border: 1px solid #ddd; padding: 8px;">Workloads with idle periods between traffic spikes, tolerant of cold starts</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Asynchronous Inference</td> <td style="border: 1px solid #ddd; padding: 8px;">Large payloads (up to 1GB), long processing times, near real-time latency requirements</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Batch transform</td> <td style="border: 1px solid #ddd; padding: 8px;">Predictions for entire datasets</td> </tr> </table> <p style="color: #555; font-size: 14px;">SageMaker also provides additional features for managing resources and optimizing inference performance:</p> <ul> <li><strong>SageMaker Edge Manager:</strong> Manage models on edge devices (e.g., smart cameras, robots, personal computers, mobile devices)</li> <li><strong>Neo:</strong> Optimize various types of models (Gluon, Keras, MXNet, PyTorch, TensorFlow, TensorFlow-Lite, ONNX) for inference on different platforms and processors</li> </ul> <p style="color: #555; font-size: 14px;">Key points to remember:</p> <ul> <li>Choose the deployment option that best fits your use case and requirements.</li> <li>Consider factors such as latency, payload size, processing time, and traffic patterns when selecting a deployment method.</li> <li>Leverage SageMaker's additional features for managing and optimizing your deployed models.</li> <li>Explore edge deployment options for scenarios involving edge devices.</li> <li>Use model optimization tools like Neo to improve inference performance across various platforms.</li> </ul> <p style="color: #555; font-size: 14px;">For a comprehensive overview of all deployment options, refer to the "Deploy models for inference" documentation in Amazon SageMaker.</p>

		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Services</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            
		</div>
	</div>
	
	<br/>
	
</div>



<div class="container mt-5">
	<h3 class="text-primary h4">Services</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            
		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Services</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            
		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Services</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            
		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Services</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            
		</div>
	</div>
	
	<br/>
	
</div>

<br/>
<br/>
<footer class="_fixed-bottom">
<div class="container-fluid p-2 bg-primary text-white text-center">
  <h6>christoferson.github.io 2023</h6>
  <!--<div style="font-size:8px;text-decoration:italic;">about</div>-->
</div>
</footer>

</body>
</html>
