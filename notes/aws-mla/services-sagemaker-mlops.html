<!DOCTYPE html>
<html lang="en-US">
<head>
	<meta charset="utf-8">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	
	<!-- Open Graph / Facebook -->
	<meta property="og:type" content="website">
	<meta property="og:locale" content="en_US">
	<meta property="og:url" content="https://christoferson.github.io/">
	<meta property="og:site_name" content="christoferson.github.io">
	<meta property="og:title" content="Meta Tags Preview, Edit and Generate">
	<meta property="og:description" content="Christoferson Chua GitHub Page">

	<!-- Twitter -->
	<meta property="twitter:card" content="summary_large_image">
	<meta property="twitter:url" content="https://christoferson.github.io/">
	<meta property="twitter:title" content="christoferson.github.io">
	<meta property="twitter:description" content="Christoferson Chua GitHub Page">
	
	<script type="application/ld+json">{
		"name": "christoferson.github.io",
		"description": "Machine Learning",
		"url": "https://christoferson.github.io/",
		"@type": "WebSite",
		"headline": "christoferson.github.io",
		"@context": "https://schema.org"
	}</script>

    
	
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet" />
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js"></script>
  
	<title>Christoferson Chua</title>
	<meta name="title" content="Christoferson Chua | GitHub Page | Machine Learning">
	<meta name="description" content="Christoferson Chua GitHub Page - Machine Learning">
	<meta name="keywords" content="Backend,Java,Spring,Aws,Python,Machine Learning">
	
	<link rel="stylesheet" href="style.css">
	
    <style>
        details {
            border: 1px solid #aaa;
            border-radius: 2px;
            padding: .5em .5em 0;
            color: indigo;
            font-size: 12px;
        }
    
        summary {
            font-weight: bold;
            margin: -.5em -.5em 0;
            padding: .5em;
            cursor: pointer;
        }
    
        details[open] {
            padding: .5em;
        }
    
        details[open] summary {
            border-bottom: 1px solid #aaa;
            margin-bottom: .5em;
        }
    </style>

</head>
<body>

<div class="container-fluid p-5 bg-primary text-white text-center">
  <h1>Machine Learning Engineer Associate (MLA) - Services SageMaker - ML Ops</h1>  
</div>



<div style="color: darkmagenta;font-size: 20px;padding:5px;">Model Deploy</div>
<hr style="height: 12px;background-color:#0066cc"/>




<div class="container mt-5">
	<h3 class="text-primary h4">Why Should You Use MLOps?</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Implement MLOps</span></p> <p>Amazon SageMaker supports features to implement machine learning models in production environments with continuous integration and deployment. The following topics give information about how to set up MLOps infrastructure when using SageMaker.</p> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Why Should You Use MLOps?</span></p> <p>MLOps, or Machine Learning Operations, is a methodology built on applying DevOps practices to machine learning workloads. It helps in improving delivery time, reducing defects, and making data science more productive. MLOps focuses on the intersection of data science and data engineering in combination with existing DevOps practices to streamline model delivery across the machine learning development lifecycle.</p> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Challenges with MLOps</span></p> <p>While integrating MLOps into machine learning workloads, you might face the following challenges:</p> <ul> <li><strong>Project management:</strong> Integrating data scientists into cross-functional teams and translating business requirements into technical requirements.</li> <li><strong>Communication and collaboration:</strong> Building visibility on ML projects and enabling collaboration across different stakeholders.</li> <li><strong>Everything is code:</strong> Managing production data in development activities, longer experimentation lifecycles, and unique metrics in evaluating model performance.</li> <li><strong>CI/CD:</strong> Versioning source data, initiating pipeline runs when data changes, and incorporating model training and retraining in build phases.</li> <li><strong>Monitoring and logging:</strong> Capturing model training metrics, experiment tracking, and monitoring deployed ML models.</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Benefits of MLOps</span></p> <p>Adopting MLOps practices provides the following benefits:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Benefit</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Productivity</td> <td style="border: 1px solid #ddd; padding: 8px;">Self-service environments with access to curated data sets allow data engineers and scientists to move faster.</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Repeatability</td> <td style="border: 1px solid #ddd; padding: 8px;">Automating steps in the MLDC ensures a repeatable process for model training, evaluation, versioning, and deployment.</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Reliability</td> <td style="border: 1px solid #ddd; padding: 8px;">Incorporating CI/CD practices allows for quick deployment with increased quality and consistency.</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Auditability</td> <td style="border: 1px solid #ddd; padding: 8px;">Versioning all inputs and outputs demonstrates exactly how the model was built and where it was deployed.</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Data and model quality</td> <td style="border: 1px solid #ddd; padding: 8px;">MLOps enables enforcing policies to guard against model bias and track changes to data properties and model quality over time.</td> </tr> </table> <p>By implementing MLOps practices, organizations can achieve faster time-to-market for ML projects and improve the overall quality and reliability of their machine learning workflows.</p>

			<hr />

			<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">SageMaker Experiments</span></p> <p>Amazon SageMaker Experiments helps track inputs and outputs across training iterations to improve repeatability and collaboration. It offers the following features:</p> <ul> <li>Track parameters, metrics, datasets, and artifacts related to model training jobs</li> <li>Visualize in-progress training jobs</li> <li>Share experiments within your team</li> <li>Deploy models directly from an experiment</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">SageMaker Workflows</span></p> <p>Amazon SageMaker offers fully managed workflow services to implement CI/CD practices for your ML lifecycle. The available workflow technologies include:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Workflow Technology</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Pipelines</td> <td style="border: 1px solid #ddd; padding: 8px;">Tool for building and managing ML pipelines</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Kubernetes Orchestration</td> <td style="border: 1px solid #ddd; padding: 8px;">Custom operators for Kubernetes clusters and components for Kubeflow Pipelines</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">SageMaker Notebook Jobs</td> <td style="border: 1px solid #ddd; padding: 8px;">On-demand or scheduled non-interactive batch runs of Jupyter notebooks</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Airflow Workflows</td> <td style="border: 1px solid #ddd; padding: 8px;">SageMaker APIs to export configurations for Airflow workflows</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">AWS Step Functions</td> <td style="border: 1px solid #ddd; padding: 8px;">Multi-step ML workflows in Python that orchestrate SageMaker infrastructure</td> </tr> </table> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Pipelines</span></p> <p>Amazon SageMaker Pipelines is a purpose-built workflow orchestration service for automating ML development. Key advantages include:</p> <ul> <li><strong>Auto-scaling serverless infrastructure:</strong> Focus on ML tasks without managing orchestration infrastructure</li> <li><strong>Intuitive user experience:</strong> Create and manage pipelines through visual editor, SDK, APIs, or JSON</li> <li><strong>AWS integrations:</strong> Seamless integration with SageMaker features and other AWS services</li> <li><strong>Reduced costs:</strong> Pay only for the SageMaker Studio environment and underlying jobs orchestrated by Pipelines</li> <li><strong>Auditability and lineage tracking:</strong> Track data history within pipeline execution using ML Lineage Tracking</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Pipelines Overview</span></p> <p>An Amazon SageMaker pipeline is a series of interconnected steps in a directed acyclic graph (DAG). Key points:</p> <ul> <li>Define pipelines using drag-and-drop UI, Pipelines SDK, or pipeline definition JSON schema</li> <li>DAG structure determined by data dependencies between steps</li> <li>Data dependencies created when properties of a step's output are passed as input to another step</li> </ul> <p>By leveraging these SageMaker workflow technologies, you can efficiently automate and scale your ML development process, improving collaboration, repeatability, and overall productivity in your ML projects.</p>

			<hr />

			<p style="color: #333; font-size: 16px;">Amazon SageMaker Pipelines are composed of steps that define the actions and relationships within the pipeline. Here's an overview of the key concepts and step types:</p> <p style="color: #333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Step Types:</span></p> <ol> <li style="color: #333; font-size: 16px;"><strong>Processing Step:</strong> For data processing jobs</li> <li style="color: #333; font-size: 16px;"><strong>Training Step:</strong> For model training jobs</li> <li style="color: #333; font-size: 16px;"><strong>Tuning Step:</strong> For hyperparameter tuning jobs</li> <li style="color: #333; font-size: 16px;"><strong>Model Step:</strong> For creating or registering SageMaker models</li> <li style="color: #333; font-size: 16px;"><strong>Create Model Step:</strong> Specifically for creating SageMaker models</li> <li style="color: #333; font-size: 16px;"><strong>Register Model Step:</strong> For registering models in the SageMaker Model Registry</li> <li style="color: #333; font-size: 16px;"><strong>Transform Step:</strong> For batch transformation jobs</li> <li style="color: #333; font-size: 16px;"><strong>Condition Step:</strong> For conditional branching in the pipeline</li> <li style="color: #333; font-size: 16px;"><strong>Callback Step:</strong> For integrating custom processes or AWS services</li> <li style="color: #333; font-size: 16px;"><strong>Lambda Step:</strong> For running AWS Lambda functions</li> <li style="color: #333; font-size: 16px;"><strong>ClarifyCheck Step:</strong> For bias analysis and model explainability</li> <li style="color: #333; font-size: 16px;"><strong>QualityCheck Step:</strong> For data and model quality checks</li> <li style="color: #333; font-size: 16px;"><strong>EMR Step:</strong> For processing Amazon EMR steps</li> <li style="color: #333; font-size: 16px;"><strong>Fail Step:</strong> For stopping pipeline execution when conditions aren't met</li> </ol> <p style="color: #333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Key Concepts:</span></p> <ul> <li style="color: #333; font-size: 16px;"><strong>Step Properties:</strong> Used to create data dependencies between steps</li> <li style="color: #333; font-size: 16px;"><strong>Step Parallelism:</strong> Control concurrent step execution with ParallelismConfiguration</li> <li style="color: #333; font-size: 16px;"><strong>Data Dependency:</strong> Define relationships between steps using step properties</li> <li style="color: #333; font-size: 16px;"><strong>Custom Dependency:</strong> Create dependencies without direct data connections using DependsOn</li> <li style="color: #333; font-size: 16px;"><strong>Custom Images:</strong> Use SageMaker Deep Learning Container images or your own containers</li> </ul> <p style="color: #333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Best Practices:</span></p> <ul> <li style="color: #333; font-size: 16px;">Use appropriate step types for specific tasks in your ML workflow</li> <li style="color: #333; font-size: 16px;">Leverage step properties to create efficient data dependencies</li> <li style="color: #333; font-size: 16px;">Control step parallelism to optimize resource usage</li> <li style="color: #333; font-size: 16px;">Use custom dependencies when direct data connections aren't applicable</li> <li style="color: #333; font-size: 16px;">Utilize condition steps for dynamic pipeline behavior</li> <li style="color: #333; font-size: 16px;">Integrate custom processes with callback and Lambda steps</li> <li style="color: #333; font-size: 16px;">Implement quality checks and bias analysis using ClarifyCheck and QualityCheck steps</li> </ul> <p style="color: #333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Example: Creating a Training Step</span></p> <table style="border-collapse: collapse; width: 100%;"> <tr> <td style="border: 1px solid #ddd; padding: 8px; font-size: 16px;"> <pre style="margin: 0; white-space: pre-wrap;"> from sagemaker.workflow.steps import TrainingStep from sagemaker.workflow.pipeline_context import PipelineSession
sklearn_train = SKLearn(..., sagemaker_session=PipelineSession())

step_train = TrainingStep( name="ModelTrain", step_args=sklearn_train.fit(inputs=TrainingInput( s3_data=step_process.properties.ProcessingOutputConfig.Outputs["train_data"].S3Output.S3Uri )) ) </pre> </td>

</tr> </table> <p style="color: #333; font-size: 16px;">By understanding and effectively using these step types and concepts, you can create complex, flexible, and efficient machine learning workflows with Amazon SageMaker Pipelines.</p>

		<hr />

		<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Kubernetes Orchestration</span></p> <p>Amazon SageMaker offers two main options for orchestrating training and inference jobs with Kubernetes:</p> <ul> <li>SageMaker Operators for Kubernetes</li> <li>SageMaker Components for Kubeflow Pipelines</li> </ul> <p>These tools allow developers and data scientists to leverage SageMaker's machine learning-optimized managed service while working within their familiar Kubernetes environments.</p> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">SageMaker Operators for Kubernetes</span></p> <p>SageMaker Operators for Kubernetes facilitate the following:</p> <ul> <li>Training, tuning, and deploying ML models in SageMaker from a Kubernetes cluster</li> <li>Creating SageMaker jobs using the Kubernetes API and command-line tools like kubectl</li> <li>Installation on Kubernetes clusters in Amazon Elastic Kubernetes Service (Amazon EKS)</li> </ul> <p>Key features and use cases:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Feature</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Model Training</td> <td style="border: 1px solid #ddd; padding: 8px;">Run SageMaker training jobs from Kubernetes</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Hyperparameter Tuning</td> <td style="border: 1px solid #ddd; padding: 8px;">Perform hyperparameter optimization using SageMaker</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Inference</td> <td style="border: 1px solid #ddd; padding: 8px;">Deploy models for real-time and batch inference on SageMaker</td> </tr> </table> <p><em>Note: Familiarity with Kubernetes and its basic commands is assumed for using these operators.</em></p> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">SageMaker Components for Kubeflow Pipelines</span></p> <p>SageMaker Components for Kubeflow Pipelines enable the following:</p> <ul> <li>Creating and monitoring native SageMaker jobs from Kubeflow Pipelines</li> <li>Moving data processing and training jobs from Kubernetes clusters to SageMaker</li> <li>Leveraging SageMaker's machine learning-optimized managed service within Kubeflow workflows</li> </ul> <p>Key components and capabilities:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Component</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Capability</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Training</td> <td style="border: 1px solid #ddd; padding: 8px;">Run SageMaker training jobs within Kubeflow Pipelines</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Tuning</td> <td style="border: 1px solid #ddd; padding: 8px;">Perform hyperparameter tuning using SageMaker</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Endpoint Deployment</td> <td style="border: 1px solid #ddd; padding: 8px;">Deploy models to SageMaker endpoints for real-time inference</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Batch Transform</td> <td style="border: 1px solid #ddd; padding: 8px;">Run batch inference jobs on SageMaker</td> </tr> </table> <p><em>Note: Prior knowledge of Kubernetes and Kubeflow is recommended for using these components.</em></p> <p>By utilizing these Kubernetes orchestration tools, you can seamlessly integrate SageMaker's powerful machine learning capabilities into your existing Kubernetes-based workflows and pipelines. This integration allows you to leverage the best of both worlds: the flexibility and familiarity of Kubernetes with the scalability and performance of SageMaker's purpose-built ML infrastructure.</p>

		<hr />

		<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">SageMaker Notebook Jobs</span></p> <p>Amazon SageMaker Notebook Jobs allow you to run your Jupyter notebooks as noninteractive, scheduled jobs. This feature is useful for various scenarios, including:</p> <ul> <li>Creating regular audit reports</li> <li>Scaling up feature engineering jobs</li> <li>Scheduling jobs for model drift monitoring</li> <li>Exploring the parameter space for better models</li> </ul> <p>Key features of SageMaker Notebook Jobs:</p> <ul> <li>Run notebooks on-demand or on a schedule</li> <li>Intuitive user interface in JupyterLab</li> <li>Scheduling via SageMaker Python SDK for pipeline workflows</li> <li>Parallel execution of multiple notebooks</li> <li>Parameterization of notebook cells</li> </ul> <p>SageMaker Notebook Jobs leverages Amazon EventBridge, SageMaker Training, and Pipelines services. It's available in various environments:</p> <ul> <li>Studio, Studio Lab, Studio Classic, or Notebook Instances</li> <li>Local setups (e.g., your local machine running JupyterLab)</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Available Options</span></p> <p>SageMaker Notebook Jobs offer numerous customization options. Here's a summary of key options:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Option</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Job name</td> <td style="border: 1px solid #ddd; padding: 8px;">Name of the job in the Notebook Jobs dashboard</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Image</td> <td style="border: 1px solid #ddd; padding: 8px;">Container image for running the notebook</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Instance type</td> <td style="border: 1px solid #ddd; padding: 8px;">EC2 instance type for running the job</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Kernel</td> <td style="border: 1px solid #ddd; padding: 8px;">Jupyter kernel used to run the notebook job</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Role ARN</td> <td style="border: 1px solid #ddd; padding: 8px;">IAM role ARN for the notebook job</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Input/Output folders</td> <td style="border: 1px solid #ddd; padding: 8px;">Locations for job inputs and outputs</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Parameters</td> <td style="border: 1px solid #ddd; padding: 8px;">Variables and values to pass to the notebook job</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Environment variables</td> <td style="border: 1px solid #ddd; padding: 8px;">Custom environment variables for the job</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Start-up/Initialization scripts</td> <td style="border: 1px solid #ddd; padding: 8px;">Scripts to run before the notebook execution</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Max retry attempts</td> <td style="border: 1px solid #ddd; padding: 8px;">Number of times to retry a failed job</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Max run time</td> <td style="border: 1px solid #ddd; padding: 8px;">Maximum duration for a job run</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Encryption options</td> <td style="border: 1px solid #ddd; padding: 8px;">Settings for encrypting job outputs and instance volume</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">VPC configuration</td> <td style="border: 1px solid #ddd; padding: 8px;">Options for running the job in a VPC</td> </tr> </table> <p>Many of these options can have preset custom default values, simplifying the job creation process. The SageMaker Python SDK also provides intelligent defaults for certain parameters.</p> <p>By leveraging SageMaker Notebook Jobs, you can automate and scale your machine learning workflows, making it easier to manage complex, recurring tasks and improve your overall productivity in machine learning projects.</p>

		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Amazon SageMaker ML Lineage Tracking</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Amazon SageMaker ML Lineage Tracking</span></p> <p>Amazon SageMaker ML Lineage Tracking is a feature that creates and stores information about the steps of a machine learning (ML) workflow, from data preparation to model deployment. It enables data scientists and model builders to:</p> <ul> <li>Reproduce workflow steps</li> <li>Track model and dataset lineage</li> <li>Establish model governance and audit standards</li> <li>Keep a running history of model discovery experiments</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Lineage Tracking Entities</span></p> <p>Tracking entities maintain a representation of all elements in your end-to-end ML workflow. SageMaker automatically creates tracking entities for various steps and allows manual creation for custom steps.</p> <p>Key concepts:</p> <ul> <li>Lineage: Metadata tracking relationships between entities in ML workflows</li> <li>QueryLineage: Action to inspect lineage and discover relationships between entities</li> <li>Lineage entities: Metadata elements composing the lineage</li> <li>Cross-account lineage: Lineage spanning multiple accounts</li> </ul> <p>Types of tracking entities:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Entity Type</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Trial Component</td> <td style="border: 1px solid #ddd; padding: 8px;">Represents processing, training, and transform jobs</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Context</td> <td style="border: 1px solid #ddd; padding: 8px;">Logical grouping of other entities (e.g., experiments, trials)</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Action</td> <td style="border: 1px solid #ddd; padding: 8px;">Represents an activity (e.g., workflow step, model deployment)</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Artifact</td> <td style="border: 1px solid #ddd; padding: 8px;">Represents a URI addressable object or data</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Association</td> <td style="border: 1px solid #ddd; padding: 8px;">Links other entities</td> </tr> </table> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">SageMaker-Created Tracking Entities</span></p> <p>SageMaker automatically creates tracking entities for:</p> <ul> <li>SageMaker Jobs (Training, Processing, Transform)</li> <li>Model Packages</li> <li>Endpoints</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Querying Lineage Entities</span></p> <p>You can query lineage entities to answer various questions about your ML workflow, such as:</p> <ul> <li>Retrieving datasets used in model creation</li> <li>Identifying jobs involved in endpoint creation</li> <li>Finding models using a specific dataset</li> <li>Discovering endpoints using a particular model</li> <li>Tracing endpoints derived from a certain dataset</li> <li>Identifying pipeline executions that created training jobs</li> <li>Exploring relationships between entities for governance and reproducibility</li> </ul> <p>Lineage tracking in SageMaker provides a powerful tool for maintaining transparency, reproducibility, and governance in your machine learning workflows. By automatically capturing and allowing queries on the relationships between various components of your ML pipeline, it enables better management and understanding of your models and their development process.</p>
		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Register and Deploy Models with Model Registry</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Register and Deploy Models with Model Registry</span></p> <p>The Amazon SageMaker Model Registry provides a centralized way to manage and organize your machine learning models. It offers the following capabilities:</p> <ul> <li>Catalog models for production</li> <li>Manage model versions</li> <li>Associate metadata with models</li> <li>View information from SageMaker Model Cards</li> <li>Manage model approval status</li> <li>Deploy models to production</li> <li>Automate model deployment with CI/CD</li> <li>Share models with other users</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Key Concepts</span></p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Concept</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Model Group</td> <td style="border: 1px solid #ddd; padding: 8px;">A container for different versions of a model</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Model Version</td> <td style="border: 1px solid #ddd; padding: 8px;">A specific iteration of a model within a Model Group</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Model Registry Collection</td> <td style="border: 1px solid #ddd; padding: 8px;">A category that can contain multiple Model Groups</td> </tr> </table> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Typical Workflow</span></p> <ol> <li>Create a Model Group</li> <li>Create an ML pipeline that trains a model</li> <li>For each pipeline run, create and register a model version in the Model Group</li> <li>Optionally, add the Model Group to one or more Model Registry Collections</li> </ol> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Model Registry Structure</span></p> <p>The SageMaker Model Registry is organized as follows:</p> <ul> <li>Model (Package) Groups contain model packages</li> <li>Each model package corresponds to a trained model</li> <li>Model package versions are numerical, starting at 1 and incrementing with each new addition</li> <li>Model Groups can be added to one or more Collections</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Types of Model Packages</span></p> <p>SageMaker has two types of model packages:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Type</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">AWS Marketplace</td> <td style="border: 1px solid #ddd; padding: 8px;">Not versionable, not associated with Model Groups</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Model Registry</td> <td style="border: 1px solid #ddd; padding: 8px;">Versioned, must be associated with a Model Group</td> </tr> </table> <p>The ARN structure for Model Registry model packages is:</p> <p><code>arn:aws:sagemaker:region:account:model-package-group/version</code></p> <p>By using the SageMaker Model Registry, you can effectively manage your machine learning models throughout their lifecycle, from development to deployment and beyond. This centralized approach helps maintain organization, versioning, and governance of your models, facilitating easier collaboration and deployment processes.</p>
            
			<hr />

			<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Model Registry Collections</span></p> <p>Collections in the SageMaker Model Registry allow you to group related registered models and organize them hierarchically for improved discoverability. Key points about Collections:</p> <ul> <li>Group related models (e.g., by domain: NLP-models, CV-models)</li> <li>Organize models in tree structures through nested Collections</li> <li>Operations on Collections don't alter underlying registered models</li> <li>Manageable via Amazon SageMaker Studio UI or Python SDK</li> </ul> <p>The Collections tab in the Model Registry allows you to:</p> <ul> <li>Create Collections</li> <li>Add Model Groups to a Collection</li> <li>Move Model Groups between Collections</li> <li>Remove Model Groups or Collections from other Collections</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Constraints</span></p> <p>When working with Collections, be aware of the following constraints:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Constraint Type</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">VPC</td> <td style="border: 1px solid #ddd; padding: 8px;">Collections are not supported in VPC mode</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Operation Limits</td> <td style="border: 1px solid #ddd; padding: 8px;">Max 10 Model Groups for add/remove/move operations</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Collection Deletion</td> <td style="border: 1px solid #ddd; padding: 8px;">Collections must be empty to be deleted</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Nesting</td> <td style="border: 1px solid #ddd; padding: 8px;">A Collection can only belong to one parent Collection</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Tag Limits</td> <td style="border: 1px solid #ddd; padding: 8px;">Model Groups can belong to max 48 Collections</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Path Length</td> <td style="border: 1px solid #ddd; padding: 8px;">Collection's absolute path max 256 characters</td> </tr> </table> <p><strong>Important:</strong> Do not alter or delete tag rules or tags belonging to Collections or Model Groups, as this prevents Collection operations.</p> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Amazon SageMaker Model Registry FAQ</span></p> <p><strong>Q: How should I organize models into Model Groups and model packages?</strong></p> <p>A: Model packages are versioned entities in the Model Registry. Each new retrained model is versioned and assigned to a Model Group. Model Groups can contain multiple versioned models.</p> <p><strong>Q: How does the SageMaker Model Registry differ from Amazon ECR?</strong></p> <p>A: The Model Registry is a metadata store for ML models, while Amazon ECR stores containers. Model Registry contains versioned model packages with S3 URIs for model files and ECR URIs for serving containers.</p> <p><strong>Q: How do I tag model packages in the Model Registry?</strong></p> <p>A: Versioned model packages don't support tags. Use CustomerMetadataProperties for key-value pairs. Model package groups support tagging.</p> <p><strong>Q: How should I assign model package groups to a project?</strong></p> <p>A: To assign model groups to a project:</p> <ol> <li>Get project tags using the ListTags API</li> <li>Apply tags to model package group: <ul> <li>For new groups: Use CreateModelPackageGroup API</li> <li>For existing groups: Use AddTags API</li> <li>When using Pipelines: Use pipeline.create(), pipeline.upsert(), or RegisterModel step</li> </ul> </li> </ol> <p>By understanding these concepts and constraints, you can effectively use the SageMaker Model Registry to organize and manage your machine learning models at scale.</p>

			<hr />
			<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Model Deployment in SageMaker</span></p> <p>After training and approving a model for production, Amazon SageMaker offers various options for deploying your model to an endpoint for real-time inference. Key aspects of model deployment in SageMaker include:</p> <ul> <li>Multiple inference options to suit different workloads</li> <li>Configurable endpoints with customizable instance types and numbers</li> <li>Advanced deployment techniques for optimizing performance and maintaining availability</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Deployment Techniques</span></p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Technique</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Shadow Testing</td> <td style="border: 1px solid #ddd; padding: 8px;">Deploy a new model or infrastructure in shadow mode to test performance without affecting production traffic</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Deployment Guardrails</td> <td style="border: 1px solid #ddd; padding: 8px;">Control the switch from current to new models using methods like blue/green or canary testing</td> </tr> </table> <p>For detailed information on model deployment, refer to the SageMaker documentation on "Deploy models for inference".</p> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">SageMaker Model Monitor</span></p> <p>Amazon SageMaker Model Monitor is a tool for monitoring the performance of deployed models in real-time. It helps maintain model quality by detecting violations of user-defined thresholds across various aspects:</p> <ul> <li>Data quality</li> <li>Model quality</li> <li>Bias drift</li> <li>Feature attribution drift</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Key Features of Model Monitor</span></p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Feature</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Configurable Alerts</td> <td style="border: 1px solid #ddd; padding: 8px;">Set up alerts for prompt troubleshooting of violations</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Integration with SageMaker Clarify</td> <td style="border: 1px solid #ddd; padding: 8px;">Improved visibility into potential bias</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Real-time Monitoring</td> <td style="border: 1px solid #ddd; padding: 8px;">Continuous monitoring of model performance in production</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Retraining Initiation</td> <td style="border: 1px solid #ddd; padding: 8px;">Quickly initiate model retraining when violations are detected</td> </tr> </table> <p>Model Monitor helps ensure the ongoing quality and reliability of your deployed models by providing continuous monitoring and alerting capabilities. This allows you to maintain the performance of your models in production and quickly address any issues that may arise.</p> <p>For more detailed information on using SageMaker Model Monitor, refer to the SageMaker documentation on "Monitor data and model quality with Amazon SageMaker Model Monitor".</p> <p>By leveraging these deployment and monitoring capabilities, you can ensure that your machine learning models perform optimally in production environments, maintain their quality over time, and quickly adapt to changing conditions or requirements.</p>

			<hr />
			<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Automate MLOps with SageMaker Projects</span></p> <p>SageMaker Projects enable the creation of end-to-end ML solutions with CI/CD, orchestrating and managing various aspects of the ML lifecycle:</p> <ul> <li>Building custom images for processing, training, and inference</li> <li>Data preparation and feature engineering</li> <li>Training models</li> <li>Evaluating models</li> <li>Deploying models</li> <li>Monitoring and updating models</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">What is a SageMaker Project?</span></p> <p>SageMaker Projects help organizations standardize developer environments for data scientists and CI/CD systems for MLOps engineers. Key features include:</p> <ul> <li>Provisioning from AWS Service Catalog using custom or SageMaker-provided templates</li> <li>Dependency management</li> <li>Code repository management</li> <li>Build reproducibility</li> <li>Artifact sharing</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">When to Use a SageMaker Project</span></p> <p>SageMaker Projects are beneficial when:</p> <ul> <li>Teams need scalable code consistency and version control</li> <li>Organizations require tight control over MLOps resources</li> <li>There's a need for collaboration across teams</li> <li>Standardization of ML infrastructure is desired</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Components of a SageMaker Project</span></p> <p>A typical SageMaker Project may include:</p> <ul> <li>One or more repositories with sample code</li> <li>A SageMaker pipeline for data preparation, training, evaluation, and deployment</li> <li>A CodePipeline or Jenkins pipeline for CI/CD</li> <li>A model group containing model versions</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Amazon SageMaker MLOps FAQ</span></p> <p><strong>Q: Do I need to use the SageMaker Python SDK to create a SageMaker pipeline?</strong></p> <p>A: No, you can also use boto3 or AWS CloudFormation. The SageMaker SDK simplifies pipeline definition creation.</p> <p><strong>Q: Why do I see a repack step in my SageMaker pipeline?</strong></p> <p>A: The repack step is added when a custom inference script needs to be included in the model file.</p> <p><strong>Q: Can I use SageMaker Experiments with SageMaker Pipelines?</strong></p> <p>A: Yes, SageMaker Pipelines is natively integrated with SageMaker Experiments.</p> <p><strong>Q: How do we pass the model file Amazon S3 URL from the train step to the model register step?</strong></p> <p>A: You can reference the model location as a property of the training step.</p> <p><strong>Q: What's the recommended way to manage dependencies for different SageMaker Pipelines steps?</strong></p> <p>A: Use a SageMaker Projects template to implement image-building CI/CD.</p> <p><strong>Q: How do I provide SageMaker Project access to specific user profiles in Amazon SageMaker Studio Classic?</strong></p> <p>A: Add each role that requires access to the Amazon SageMaker Solutions and ML Ops products Portfolio in the service catalog.</p> <p><strong>Q: In Pipelines, can I specify a unique output path for a pipeline step?</strong></p> <p>A: Yes, you can use ExecutionVariables and the Join function to specify your output location.</p> <p><strong>Q: What's the best way to reproduce my model in SageMaker?</strong></p> <p>A: Use SageMaker's Lineage Tracking service to track all metadata associated with your model training and deployment workflows.</p> <p>SageMaker Projects and MLOps features provide a comprehensive solution for managing the entire machine learning lifecycle, from development to deployment and monitoring. By leveraging these tools, organizations can streamline their ML workflows, improve collaboration, and maintain high standards of model quality and reproducibility.</p>


		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Monitor data and model quality with Amazon SageMaker Model Monitor</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Monitor Data and Model Quality with Amazon SageMaker Model Monitor</span></p> <p>Amazon SageMaker Model Monitor provides continuous monitoring of machine learning models in production. It offers the following capabilities:</p> <ul> <li>Continuous monitoring with real-time endpoints</li> <li>Continuous monitoring with regular batch transform jobs</li> <li>On-schedule monitoring for asynchronous batch transform jobs</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Types of Monitoring</span></p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Monitoring Type</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Data Quality</td> <td style="border: 1px solid #ddd; padding: 8px;">Monitor drift in data quality</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Model Quality</td> <td style="border: 1px solid #ddd; padding: 8px;">Monitor drift in model quality metrics (e.g., accuracy)</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Bias Drift</td> <td style="border: 1px solid #ddd; padding: 8px;">Monitor bias in model predictions</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Feature Attribution Drift</td> <td style="border: 1px solid #ddd; padding: 8px;">Monitor drift in feature attribution</td> </tr> </table> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">How Amazon SageMaker Model Monitor Works</span></p> <p>The process of model monitoring involves the following steps:</p> <ol> <li>Enable data capture for real-time endpoints or batch transform jobs</li> <li>Create a baseline from the training dataset</li> <li>Create a monitoring schedule</li> <li>Inspect reports and watch for violations</li> </ol> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Capturing Data</span></p> <p>Data Capture is a feature that logs inputs to your endpoint and inference outputs from your deployed model to Amazon S3. It can be implemented for both real-time and batch model-monitor modes.</p> <p><strong>For Real-time Endpoints:</strong></p> <ul> <li>Specify Data Capture configuration when creating the endpoint</li> <li>Configure options to turn data capturing on/off at certain times</li> <li>Change sampling frequency</li> <li>Choose to encrypt inference data</li> </ul> <p><strong>For Batch Transform Jobs:</strong></p> <ul> <li>Enable Data Capture when creating the batch transform job</li> <li>Option to turn on encryption</li> <li>Generate inference ID with output to match captured data to Ground Truth data</li> </ul> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Implementation</span></p> <p>You can implement Data Capture using either the AWS SDK for Python (Boto) or the SageMaker Python SDK:</p> <p><strong>Using AWS SDK (Boto):</strong></p> <ul> <li>For real-time endpoints: Define <code>DataCaptureConfig</code> dictionary in <code>CreateEndpointConfig</code> method</li> <li>For batch transform jobs: Define <code>DataCaptureConfig</code> dictionary in <code>CreateTransformJob</code> method</li> </ul> <p><strong>Using SageMaker Python SDK:</strong></p> <ul> <li>For real-time endpoints: Import and initialize <code>DataCaptureConfig</code> class, pass to <code>sagemaker.model.Model.deploy()</code></li> <li>For batch transform jobs: Import and initialize <code>BatchDataCaptureConfig</code> class, pass to transform job instance</li> </ul> <p>By leveraging Amazon SageMaker Model Monitor and its data capture capabilities, you can proactively detect and address issues in your deployed machine learning models, ensuring their ongoing quality and performance in production environments.</p>
			<hr />
			<p>Monitor Data Quality</p>
            <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Monitor Data Quality</span></p> <p>Amazon SageMaker Model Monitor automatically monitors machine learning (ML) models in production for data quality issues. It uses rules to detect data drift and alerts you when it happens. To monitor data quality, follow these steps:</p> <ol> <li>Enable data capture</li> <li>Create a baseline</li> <li>Define and schedule data quality monitoring jobs</li> <li>Optionally use preprocessing and postprocessing scripts</li> <li>View data quality metrics</li> <li>Integrate with Amazon CloudWatch</li> <li>Interpret the results of a monitoring job</li> <li>Use SageMaker Studio to enable monitoring and visualize results (for real-time endpoints)</li> </ol> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Create a Baseline</span></p> <p>Baseline calculations of statistics and constraints are needed to detect data drift and other data quality issues. The process involves:</p> <ul> <li>Using a built-in container (sagemaker-model-monitor-analyzer) for constraint suggestion</li> <li>Using the training dataset as the baseline dataset</li> <li>Generating baseline statistics and constraints</li> </ul> <p>To create a baseline from a training dataset:</p> <pre><code> from sagemaker.model_monitor import DefaultModelMonitor from sagemaker.model_monitor.dataset_format import DatasetFormat my_default_monitor = DefaultModelMonitor( role=role, instance_count=1, instance_type='ml.m5.xlarge', volume_size_in_gb=20, max_runtime_in_seconds=3600, ) my_default_monitor.suggest_baseline( baseline_dataset=baseline_data_uri+'/training-dataset-with-header.csv', dataset_format=DatasetFormat.csv(header=True), output_s3_uri=baseline_results_uri, wait=True ) </code></pre> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Output Files</span></p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>File Name</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">statistics.json</td> <td style="border: 1px solid #ddd; padding: 8px;">Contains columnar statistics for each feature in the dataset</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">constraints.json</td> <td style="border: 1px solid #ddd; padding: 8px;">Contains the constraints on the features observed</td> </tr> </table> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Schema for Violations</span></p> <p>The violations file (constraint_violations.json) is generated as the output of a MonitoringExecution. It lists the results of evaluating the constraints against the current dataset. The following violation checks are provided:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Violation Check Type</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">data_type_check</td> <td style="border: 1px solid #ddd; padding: 8px;">Flags if data types in current execution differ from baseline</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">completeness_check</td> <td style="border: 1px solid #ddd; padding: 8px;">Flags if completeness of non-null items exceeds threshold</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">baseline_drift_check</td> <td style="border: 1px solid #ddd; padding: 8px;">Flags if distribution distance between current and baseline exceeds threshold</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">missing_column_check</td> <td style="border: 1px solid #ddd; padding: 8px;">Flags if current dataset has fewer columns than baseline</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">extra_column_check</td> <td style="border: 1px solid #ddd; padding: 8px;">Flags if current dataset has more columns than baseline</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">categorical_values_check</td> <td style="border: 1px solid #ddd; padding: 8px;">Flags if there are more unknown values in current dataset than baseline</td> </tr> </table> <p>By using these monitoring capabilities, you can ensure the ongoing quality of your data and detect potential issues that may affect your model's performance in production.</p>

			<hr />
			<p>Monitor model quality</p>
			<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Monitor Model Quality</span></p> <p>Model quality monitoring jobs compare the predictions made by a model with actual Ground Truth labels to assess the model's performance. The process involves:</p> <ol> <li>Enabling data capture</li> <li>Creating a baseline</li> <li>Defining and scheduling model quality monitoring jobs</li> <li>Ingesting Ground Truth labels and merging them with predictions</li> <li>Integrating with Amazon CloudWatch</li> <li>Interpreting results</li> <li>Using SageMaker Studio for visualization (for real-time endpoints)</li> </ol> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Create a Model Quality Baseline</span></p> <p>To create a baseline job:</p> 
<pre><code>
from sagemaker import get_execution_role, session, Session 
from sagemaker.model_monitor import ModelQualityMonitor
role = get_execution_role() 
session = Session() 
model_quality_monitor = ModelQualityMonitor( role=role, instance_count=1, 
	instance_type='ml.m5.xlarge', volume_size_in_gb=20, 
	max_runtime_in_seconds=1800, sagemaker_session=session ) 
baseline_job = model_quality_monitor.suggest_baseline( job_name="MyBaseLineJob", 
	baseline_dataset=baseline_dataset_uri, 
	dataset_format=DatasetFormat.csv(header=True), 
	output_s3_uri=baseline_results_uri, problem_type='BinaryClassification', 
	inference_attribute="prediction", probability_attribute="probability", 
	ground_truth_attribute="label" ) 
baseline_job.wait(logs=False)</code></pre>
			<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Schedule Model Quality Monitoring Jobs</span></p> <p>For real-time endpoints:</p> 
<pre><code>
from sagemaker.model_monitor import CronExpressionGenerator 
schedule = model_quality_monitor.create_monitoring_schedule( 
	monitor_schedule_name=schedule_name, 
	post_analytics_processor_script=s3_code_postprocessor_uri, 
	output_s3_uri=s3_report_path, 
	statistics=model_quality_monitor.baseline_statistics(), 
	constraints=model_quality_monitor.suggested_constraints(), 
	schedule_cron_expression=CronExpressionGenerator.hourly(), 
	enable_cloudwatch_metrics=True, 
	endpoint_input=EndpointInput( 
		endpoint_name=endpoint_name, 
		destination="/opt/ml/processing/input/endpoint", 
		start_time_offset="-PT2D", 
		end_time_offset="-PT1D", ) )
</code></pre> 
<p>For batch transform jobs:</p> 
<pre><code>
schedule = model_quality_monitor.create_monitoring_schedule(
	monitor_schedule_name=mon_schedule_name, 
	batch_transform_input=BatchTransformInput( 
		data_captured_destination_s3_uri=s3_capture_upload_path,
		destination="/opt/ml/processing/input", 
		dataset_format=MonitoringDatasetFormat.csv(header=False), 
		probability_attribute="0", 
		probability_threshold_attribute=0.5, 
		start_time_offset="-PT6H", end_time_offset="-PT0H" ), 
		ground_truth_input=gt_s3_uri, 
		output_s3_uri=s3_report_path, 
		problem_type="BinaryClassification", 
		constraints=constraints_path, 
		schedule_cron_expression=CronExpressionGenerator.hourly(), 
		enable_cloudwatch_metrics=True, )</code></pre>
<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Ingest Ground Truth Labels</span></p> <p>To match Ground Truth labels with captured prediction data:</p> <ul> <li>Use a unique identifier (eventId or inferenceId) for each record</li> <li>Upload Ground Truth data to an S3 bucket with the path format: <code>s3://bucket/prefix/yyyy/mm/dd/hh</code></li> <li>Structure each Ground Truth record as follows:</li> </ul> 
<pre><code>
{
	"groundTruthData": { "data": "1", "encoding": "CSV" }, 
	"eventMetadata": { "eventId": "aaaa-bbbb-cccc" }, 
	"eventVersion": "0"
}</code></pre>
<p>When creating the monitoring job, specify the location of Ground Truth labels:</p> <ul> <li>For AWS SDK for Python (Boto3): Use the <code>S3Uri</code> field of the <code>GroundTruthS3Input</code> parameter in <code>create_model_quality_job_definition</code></li> <li>For SageMaker Python SDK: Use the <code>ground_truth_input</code> parameter in <code>create_monitoring_schedule</code> of the <code>ModelQualityMonitor</code> object</li> </ul> <p>By following these steps, you can effectively monitor the quality of your machine learning models in production, ensuring they continue to perform as expected and identifying any degradation in model performance over time.</p>
			<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Model Quality Metrics and Amazon CloudWatch Monitoring</span></p> <p>Model quality monitoring jobs compute different metrics to evaluate the quality and performance of machine learning models. The metrics vary based on the type of ML problem: regression, binary classification, or multiclass classification.</p> <p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Regression Metrics</span></p> 
<pre><code>
"regression_metrics" : {
	"mae" : { "value" : 0.3711832061068702, 
		"standard_deviation" : 0.0037566388129940394 }, 
	"mse" : { "value" : 0.3711832061068702, 
		"standard_deviation" : 0.0037566388129940524 },
	"rmse" : { "value" : 0.609248066149471, 
		"standard_deviation" : 0.003079253267651125 },
	"r2" : { "value" : -1.3766111872212665, 
		"standard_deviation" : 0.022653980022771227 } }</code></pre>
<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Binary Classification Metrics</span></p>
<pre><code>
"binary_classification_metrics" : { 
	"confusion_matrix" : { 
		"0" : { "0" : 1, "1" : 2 }, 
		"1" : { "0" : 0, "1" : 1 } 
	}, 
	"recall" : { "value" : 1.0, "standard_deviation" : "NaN" }, 
	"precision" : { "value" : 0.3333333333333333, 
	"standard_deviation" : "NaN" }, 
	"accuracy" : { "value" : 0.5, "standard_deviation" : "NaN" }, 
	"auc" : { "value" : 1.0, "standard_deviation" : "NaN" }, 
	"f1" : { "value" : 0.5, "standard_deviation" : "NaN" } // ... }</code></pre>
<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Multiclass Classification Metrics</span></p>
<pre><code>
"multiclass_classification_metrics" : {
	"confusion_matrix" : { 
		"0" : { "0" : 1180, "1" : 510 }, 
		"1" : { "0" : 268, "1" : 138 } }, 
	"accuracy" : { "value" : 0.6288167938931297, 
		"standard_deviation" : 0.00375663881299405 }, 
	"weighted_recall" : { "value" : 0.6288167938931297, 
		"standard_deviation" : 0.003756638812994008 }, 
	"weighted_precision" : { "value" : 0.6983172269629505, 
		"standard_deviation" : 0.006195912915307507 }, 
	"weighted_f1" : { "value" : 0.6571162346664904, 
		"standard_deviation" : 0.004385008075019733 } // ... other metrics }</code></pre>
<p style="color: #333333; font-size: 16px;"><span style="color: #0066cc; font-weight: bold;">Monitoring Model Quality Metrics with CloudWatch</span></p> <p>To enable CloudWatch monitoring:</p> <ol> <li>Set <code>enable_cloudwatch_metrics</code> to <code>True</code> when creating the monitoring schedule.</li> <li>Model quality metrics will appear in the following namespaces: <ul> <li>For real-time endpoints: <code>aws/sagemaker/Endpoints/model-metrics</code></li> <li>For batch transform jobs: <code>aws/sagemaker/ModelMonitoring/model-metrics</code></li> </ul> </li> </ol> <p>To create a CloudWatch alarm:</p> <ol> <li>Go to the CloudWatch console</li> <li>Choose "Alarms" from the navigation pane</li> <li>Click "Create alarm"</li> <li>Select the metric you want to monitor</li> <li>Set the threshold and condition for the alarm</li> <li>Configure notifications (e.g., SNS topic)</li> <li>Name and describe your alarm</li> <li>Click "Create alarm" to finish</li> </ol> <p><strong>Note:</strong> Standard deviation for metrics is provided only when at least 200 samples are available. Model Monitor computes standard deviation by randomly sampling 80% of the data five times, computing the metric, and taking the standard deviation of those results.</p> <p>By monitoring these metrics in CloudWatch, you can set up automated alerts to notify you when your model's performance deviates from expected levels, allowing for timely interventions and maintenance of model quality.</p>

<hr />
<p>Monitor Bias Drift for Models in Production</p>
<div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;"> <p style="color: #333; font-size: 16px; font-weight: bold;">Monitoring Bias Drift in Production Models with Amazon SageMaker Clarify</p> <p>Amazon SageMaker Clarify provides tools for monitoring bias drift in deployed machine learning models. This comprehensive guide covers the key aspects of bias monitoring:</p> <ul> <li>Importance of continuous bias monitoring</li> <li>Setting up bias drift detection</li> <li>Creating a bias drift baseline</li> <li>Understanding bias drift violations</li> </ul> <p style="color: #0066cc; font-size: 14px;">Why Monitor Bias Drift?</p> <p>Bias can be introduced or exacerbated in deployed models due to differences between training data and live data. Reasons include:</p> <ul> <li>Temporary changes in data distribution (e.g., holiday seasons)</li> <li>Permanent shifts in real-world conditions</li> <li>Discrepancies between training and production environments</li> </ul> <p style="color: #0066cc; font-size: 14px;">Setting Up Bias Drift Detection</p> <p>SageMaker Clarify allows you to:</p> <ul> <li>Monitor bias metrics continuously</li> <li>Set thresholds for acceptable bias levels</li> <li>Receive automated alerts when thresholds are exceeded</li> <li>Perform checks at regular intervals (e.g., every 2 days)</li> </ul> <p style="color: #0066cc; font-size: 14px;">Creating a Bias Drift Baseline</p> <p>Steps to create a baseline:</p> <ol> <li>Configure data inputs and sensitive groups</li> <li>Specify prediction capture method</li> <li>Set up model and post-training bias metrics</li> <li>Start the baselining job</li> </ol> <p>Key configurations:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Configuration</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Purpose</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">DataConfig</td> <td style="border: 1px solid #ddd; padding: 8px;">Specifies dataset information</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">BiasConfig</td> <td style="border: 1px solid #ddd; padding: 8px;">Defines sensitive groups and facets</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">ModelPredictedLabelConfig</td> <td style="border: 1px solid #ddd; padding: 8px;">Configures prediction extraction</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">ModelConfig</td> <td style="border: 1px solid #ddd; padding: 8px;">Sets up model inferencing details</td> </tr> </table> <p style="color: #0066cc; font-size: 14px;">Understanding Bias Drift Violations</p> <p>Bias drift violations are logged when monitored metrics exceed baseline thresholds. The violation file includes:</p> <ul> <li>Facet name and value</li> <li>Metric name (e.g., "CI" for class imbalance)</li> <li>Constraint check type (currently only "bias_drift_check")</li> <li>Description of the violation</li> </ul> <p>Example violation:</p> 
<pre style="background-color: #f5f5f5; padding: 10px; border-radius: 5px;">
{ "facet": "Age", "facet_value": "40", "metric_name": "DPPL", 
	"constraint_check_type": "bias_drift_check", 
	"description": "Value -0.0791244970125596 does not meet 
		the constraint requirement" }</pre>
<p>By leveraging these tools, data scientists and ML engineers can proactively detect and address bias issues that may emerge after model deployment, ensuring fairer and more reliable AI systems over time.</p> </div>

<div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;"> <p style="color: #333; font-size: 16px; font-weight: bold;">CloudWatch Metrics for Bias Drift Analysis in SageMaker Clarify</p> <p>Amazon SageMaker Clarify provides CloudWatch metrics for comprehensive bias drift analysis. This guide outlines the key aspects of using these metrics:</p> <p style="color: #0066cc; font-size: 14px;">Metric Namespaces</p> <p>Bias drift monitoring jobs publish metrics to the following CloudWatch namespaces:</p> <ul> <li>For real-time endpoints: <code>aws/sagemaker/Endpoints/bias-metrics</code></li> <li>For batch transform jobs: <code>aws/sagemaker/ModelMonitoring/bias-metrics</code></li> </ul> <p style="color: #0066cc; font-size: 14px;">Metric Naming Convention</p> <p>The CloudWatch metric name follows this pattern:</p> <pre style="background-color: #f5f5f5; padding: 10px; border-radius: 5px;"> bias_metric_[ShortMetricName] </pre> <p>For example, <code>bias_metric_CI</code> represents the bias metric for class imbalance (CI).</p> <p style="color: #0066cc; font-size: 14px;">Metric Properties</p> <p>Each metric includes the following properties:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Property</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Endpoint</td> <td style="border: 1px solid #ddd; padding: 8px;">Name of the monitored endpoint (if applicable)</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">MonitoringSchedule</td> <td style="border: 1px solid #ddd; padding: 8px;">Name of the monitoring job schedule</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">BiasStage</td> <td style="border: 1px solid #ddd; padding: 8px;">Stage of bias drift monitoring (Pre-training or Post-Training)</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Label</td> <td style="border: 1px solid #ddd; padding: 8px;">Name of the target feature</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">LabelValue</td> <td style="border: 1px solid #ddd; padding: 8px;">Value of the target feature</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Facet</td> <td style="border: 1px solid #ddd; padding: 8px;">Name of the facet</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">FacetValue</td> <td style="border: 1px solid #ddd; padding: 8px;">Value of the facet</td> </tr> </table> <p style="color: #0066cc; font-size: 14px;">Important Notes</p> <ul> <li>+/- infinity is published as the floating point number +/- 2.348543e108</li> <li>Errors including null values are not published</li> <li>To stop publishing metrics, set <code>publish_cloudwatch_metrics</code> to <code>Disabled</code> in the Environment map of the model bias job definition</li> </ul> <p style="color: #0066cc; font-size: 14px;">Using CloudWatch Metrics</p> <p>These metrics enable you to:</p> <ul> <li>Monitor bias drift in real-time for deployed endpoints</li> <li>Track bias changes in batch transform jobs</li> <li>Set up alarms for specific bias thresholds</li> <li>Visualize bias trends over time</li> <li>Compare pre-training and post-training bias metrics</li> </ul> <p>By leveraging these CloudWatch metrics, you can gain deeper insights into bias drift patterns, set up automated monitoring, and take proactive measures to maintain fairness in your machine learning models throughout their lifecycle.</p> </div>

<hr />
<p>Monitor Feature Attribution Drift for Models in Production</p>
<div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;"> <p style="color: #333; font-size: 16px; font-weight: bold;">Monitoring Feature Attribution Drift in Production Models</p> <p>Amazon SageMaker Clarify provides tools for monitoring feature attribution drift in deployed machine learning models. This guide covers the key aspects of feature attribution monitoring:</p> <p style="color: #0066cc; font-size: 14px;">Why Monitor Feature Attribution Drift?</p> <ul> <li>Changes in live data distribution can lead to drift in feature attribution values</li> <li>Helps maintain model interpretability and fairness over time</li> <li>Allows for early detection of significant changes in model behavior</li> </ul> <p style="color: #0066cc; font-size: 14px;">Detecting Feature Attribution Drift</p> <p>SageMaker Clarify uses the Normalized Discounted Cumulative Gain (NDCG) score to compare feature attribution rankings between training and live data:</p> <ul> <li>NDCG ranges from 0 to 1, with 1 indicating no drift</li> <li>An alert is raised if NDCG falls below 0.90</li> <li>Sensitive to both ranking changes and raw attribution scores</li> </ul> <p style="color: #0066cc; font-size: 14px;">Creating a SHAP Baseline</p> <p>Steps to create a baseline for feature attribution monitoring:</p> <ol> <li>Configure data inputs and sensitive groups</li> <li>Set up prediction capture method</li> <li>Configure model and post-training metrics</li> <li>Start the baselining job</li> </ol> <p style="color: #0066cc; font-size: 14px;">Key Configurations</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Configuration</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Purpose</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">DataConfig</td> <td style="border: 1px solid #ddd; padding: 8px;">Specifies dataset information</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">SHAPConfig</td> <td style="border: 1px solid #ddd; padding: 8px;">Configures SHAP explainer settings</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">ModelConfig</td> <td style="border: 1px solid #ddd; padding: 8px;">Sets up model inferencing details</td> </tr> </table> <p style="color: #0066cc; font-size: 14px;">SHAP Configuration Options</p> <ul> <li><strong>baseline:</strong> Dataset used as baseline in Kernel SHAP algorithm</li> <li><strong>num_samples:</strong> Number of samples for Kernel SHAP algorithm</li> <li><strong>agg_method:</strong> Aggregation method for global SHAP values (mean_abs, median, mean_sq)</li> <li><strong>use_logit:</strong> Whether to apply logit function to model predictions</li> <li><strong>save_local_shap_values:</strong> Whether to save local SHAP values</li> </ul> <p style="color: #0066cc; font-size: 14px;">Example Code Snippet</p> 
<pre style="background-color: #f5f5f5; padding: 10px; border-radius: 5px;">
shap_config = SHAPConfig( baseline=shap_baseline, num_samples=100, 
	agg_method="mean_abs", save_local_shap_values=False, ) 
model_explainability_monitor.suggest_baseline( 
	data_config=model_explainability_data_config, 
	model_config=model_config, explainability_config=shap_config, ) </pre> 
<p>By leveraging these tools, data scientists and ML engineers can:</p> <ul> <li>Monitor feature attribution changes in real-time</li> <li>Set up alerts for significant shifts in feature importance</li> <li>Maintain model interpretability throughout its lifecycle</li> <li>Ensure consistent and fair model behavior in production</li> </ul> </div>


<div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;"> <p style="color: #333; font-size: 16px; font-weight: bold;">Model Feature Attribution Drift Monitoring in Amazon SageMaker</p> <p style="color: #0066cc; font-size: 14px;">Feature Attribution Drift Violations</p> <p>SageMaker Clarify detects feature attribution drift by comparing baseline constraints against current analysis results. Violations are logged in a JSON file with the following schema:</p> <ul> <li><strong>label:</strong> Name of the label or placeholder</li> <li><strong>metric_name:</strong> Name of the explainability analysis method (currently only "shap")</li> <li><strong>constraint_check_type:</strong> Type of violation (currently only "feature_attribution_drift_check")</li> <li><strong>description:</strong> Explanation of the violation</li> </ul> <p>A violation is logged if the nDCG score of global SHAP values falls below 0.9.</p> <p style="color: #0066cc; font-size: 14px;">Configuring Attribution Drift Monitoring</p> <p>Key configuration parameters include:</p> <ul> <li><strong>headers:</strong> List of feature names</li> <li><strong>methods:</strong> Specifies SHAP computation details</li> <li><strong>predictor:</strong> Model parameters for shadow endpoint</li> </ul> <p>Separate configurations are needed for CSV and JSON Lines datasets.</p> <p style="color: #0066cc; font-size: 14px;">Scheduling Monitoring Jobs</p> <p>Steps to schedule monitoring:</p> <ol> <li>Create a SHAP baseline</li> <li>Use <code>create_monitoring_schedule()</code> method</li> <li>Specify either endpoint input or batch transform input</li> </ol> <p>Example for real-time endpoint:</p>
<pre style="background-color: #f5f5f5; padding: 10px; border-radius: 5px;">
schedule = model_exp_model_monitor.create_monitoring_schedule( 
	monitor_schedule_name=schedule_name, 
	endpoint_input=EndpointInput( 
		endpoint_name=endpoint_name, 
		destination="/opt/ml/processing/input/endpoint", ) ) </pre> 
<p style="color: #0066cc; font-size: 14px;">CloudWatch Metrics for Feature Drift Analysis</p> <p>SageMaker Clarify publishes two types of metrics:</p> <ol> <li>Global SHAP value for each feature</li> <li>ExpectedValue of the metric</li> </ol> <p>Metrics are published to specific namespaces based on deployment type (real-time endpoint or batch transform).</p> <p>Metric properties include:</p> <ul> <li>Endpoint</li> <li>MonitoringSchedule</li> <li>ExplainabilityMethod</li> <li>Label</li> <li>ValueType</li> </ul> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Deployment Type</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>CloudWatch Namespace</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Real-time endpoints</td> <td style="border: 1px solid #ddd; padding: 8px;">aws/sagemaker/Endpoints/explainability-metrics</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Batch transform jobs</td> <td style="border: 1px solid #ddd; padding: 8px;">aws/sagemaker/ModelMonitoring/explainability-metrics</td> </tr> </table> <p>To disable metric publishing, set <code>publish_cloudwatch_metrics</code> to <code>Disabled</code> in the job definition.</p> </div>

		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Schedule monitoring jobs</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            <div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;"> <p style="color: #333; font-size: 16px; font-weight: bold;">Scheduling and Interpreting Model Monitoring Jobs in Amazon SageMaker</p> <p style="color: #0066cc; font-size: 14px;">Scheduling Monitoring Jobs</p> <ul> <li>Use <code>CreateMonitoringSchedule</code> API to set up recurring or one-time monitoring</li> <li>Monitoring can be scheduled for real-time endpoints or batch transform jobs</li> <li>SageMaker provides a prebuilt container for analysis, or you can use a custom container</li> </ul> <p>Example for scheduling a recurring monitor for a real-time endpoint:</p> 
			<pre style="background-color: #f5f5f5; padding: 10px; border-radius: 5px;">
my_default_monitor.create_monitoring_schedule( 
	monitor_schedule_name=mon_schedule_name, 
	endpoint_input=EndpointInput( 
			endpoint_name=endpoint_name, 
			destination="/opt/ml/processing/input/endpoint" ), 
	schedule_cron_expression=CronExpressionGenerator.hourly(), 
	enable_cloudwatch_metrics=True, ) </pre> 
			<p style="color: #0066cc; font-size: 14px;">SageMaker Model Monitor Prebuilt Container</p> <ul> <li>Image name: <code>sagemaker-model-monitor-analyzer</code></li> <li>Based on Spark 3.3.0 and Deequ 2.0.2</li> <li>Accessed via ECR URI: <code>&lt;ACCOUNT_ID&gt;.dkr.ecr.&lt;REGION_NAME&gt;.amazonaws.com/sagemaker-model-monitor-analyzer</code></li> </ul> <p style="color: #0066cc; font-size: 14px;">Interpreting Results</p> <ol> <li><strong>List Executions:</strong> Use <code>list_executions()</code> to view monitoring job runs</li> <li><strong>Inspect Specific Execution:</strong> Check status and results of individual runs</li> <li><strong>List Generated Reports:</strong> View reports generated by monitoring jobs</li> <li><strong>Violations Report:</strong> Analyze constraint violations compared to the baseline</li> </ol> <p>Example of listing violations:</p> 
			<pre style="background-color: #f5f5f5; padding: 10px; border-radius: 5px;">
violations = my_default_monitor.latest_monitoring_constraint_violations() 
constraints_df = pd.io.json.json_normalize(violations.body_dict["violations"]) 
constraints_df.head(10)</pre> <p style="color: #0066cc; font-size: 14px;">Output Files for Tabular Datasets</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>File Name</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">statistics.json</td> <td style="border: 1px solid #ddd; padding: 8px;">Contains columnar statistics for each feature (data quality monitoring only)</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">constraint_violations.json</td> <td style="border: 1px solid #ddd; padding: 8px;">Lists violations found compared to baseline statistics and constraints</td> </tr> </table> <p style="color: #0066cc; font-size: 14px;">Visualizing Results in SageMaker Studio</p> <ul> <li>Available for real-time endpoint monitoring</li> <li>View details of any monitoring job run</li> <li>Create charts comparing baseline and captured values for metrics</li> </ul> <p>By leveraging these tools and visualizations, data scientists and ML engineers can effectively monitor their deployed models, detect drift or anomalies, and maintain model performance over time.</p> </div>


		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Advanced</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
			<div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;"> <p style="color: #333; font-size: 16px; font-weight: bold;">Advanced Topics in Amazon SageMaker Model Monitoring</p> <p style="color: #0066cc; font-size: 14px;">Creating a Monitoring Schedule with AWS CloudFormation</p> <p>For real-time endpoints, you can use AWS CloudFormation with a custom resource to create a monitoring schedule. This involves two main components:</p> <ol> <li>Custom Resource in CloudFormation Template</li> <li>Lambda Function for Custom Resource</li> </ol> <p style="color: #0066cc; font-size: 14px;">1. Custom Resource in CloudFormation Template</p> 
			<pre style="background-color: #f5f5f5; padding: 10px; border-radius: 5px;"> 
{ 
"Type": "Custom::MonitoringSchedule", 
"Properties": { 
	"ServiceToken": "arn:aws:lambda:us-west-2:111111111111:function:lambda-name", 
	"ScheduleName": "YourScheduleName", 
	"EndpointName": "YourEndpointName", 
	"BaselineConstraintsUri": "s3://your-baseline-constraints/constraints.json", 
	"BaselineStatisticsUri": "s3://your-baseline-stats/statistics.json", 
	"PostAnalyticsProcessorSourceUri": "s3://your-post-processor/postprocessor.py", 
	"RecordPreprocessorSourceUri": "s3://your-preprocessor/preprocessor.py", 
	"InputLocalPath": "/opt/ml/processing/endpointdata", 
	"OutputLocalPath": "/opt/ml/processing/localpath", 
	"OutputS3URI": "s3://your-output-uri", 
	"ImageURI": "111111111111.dkr.ecr.us-west-2.amazonaws.com/your-image", 
	"ScheduleExpression": "cron(0 * ? * * *)", 
	"PassRoleArn": "arn:aws:iam::111111111111:role/AmazonSageMaker-ExecutionRole" 
}}</pre> 
		<p style="color: #0066cc; font-size: 14px;">2. Lambda Function for Custom Resource</p> <p>Key components of the Lambda function:</p> <ul> <li>Uses the Custom Resource Helper library (<code>crhelper</code>)</li> <li>Implements handlers for create, delete, and poll_create events</li> <li>Creates and deletes monitoring schedules using the SageMaker API</li> </ul> <p>Main functions:</p> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Function</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Purpose</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">create_handler</td> <td style="border: 1px solid #ddd; padding: 8px;">Called when CloudFormation sends the create event</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">delete_handler</td> <td style="border: 1px solid #ddd; padding: 8px;">Called when CloudFormation sends the delete event</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">poll_create</td> <td style="border: 1px solid #ddd; padding: 8px;">Checks if the monitoring schedule is ready</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">create_monitoring_schedule</td> <td style="border: 1px solid #ddd; padding: 8px;">Creates the monitoring schedule using SageMaker API</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">delete_monitoring_schedule</td> <td style="border: 1px solid #ddd; padding: 8px;">Deletes the monitoring schedule</td> </tr> </table> <p style="color: #0066cc; font-size: 14px;">Benefits of Using CloudFormation for Monitoring Schedules</p> <ul> <li>Automates the creation and deletion of monitoring schedules</li> <li>Allows for easy integration with other AWS resources in your stack</li> <li>Provides a repeatable and version-controlled way to manage monitoring schedules</li> <li>Enables customization of monitoring parameters through CloudFormation template</li> </ul> <p>By using this CloudFormation custom resource approach, you can seamlessly incorporate model monitoring into your infrastructure-as-code practices, ensuring consistent and automated setup of monitoring schedules for your SageMaker endpoints.</p> </div>
            
		<hr />

		<div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;"> <p style="color: #333; font-size: 16px; font-weight: bold;">Model Monitor FAQs</p> <p style="color: #0066cc; font-size: 14px;">Key Features and Functionality</p> <ul> <li>Monitors model behavior along four dimensions: Data quality, Model quality, Bias drift, and Feature Attribution drift</li> <li>Automates model monitoring, eliminating the need for manual monitoring or additional tooling</li> <li>Uses Data Capture to log inputs and outputs from deployed models to Amazon S3</li> <li>Supports Ground Truth integration for model quality and bias monitoring</li> </ul> <p style="color: #0066cc; font-size: 14px;">Customization and Flexibility</p> <ul> <li>Allows customization of monitoring schedules using pre-processing and post-processing scripts</li> <li>Supports bringing your own container (BYOC) for specialized monitoring needs</li> <li>Enables monitoring of NLP and CV models through custom containers</li> </ul> <p style="color: #0066cc; font-size: 14px;">Baselines and Monitoring</p> <ul> <li>Uses baselines to compare real-time or batch predictions</li> <li>Supports creation of custom baselines</li> <li>Allows on-demand monitoring jobs through SageMaker Processing jobs</li> </ul> <p style="color: #0066cc; font-size: 14px;">Integration and Setup</p> <ul> <li>Integrates with SageMaker Python SDK, Pipelines, SageMaker Studio Classic, and SageMaker Model Dashboard</li> <li>Provides unified monitoring across all models through SageMaker Model Dashboard</li> </ul> <p style="color: #0066cc; font-size: 14px;">Limitations and Considerations</p> <ul> <li>Does not support multi-model endpoints</li> <li>Data Capture and monitoring schedule must be in the same AWS region</li> <li>Calculates metrics and statistics for output, not input</li> </ul> <p style="color: #0066cc; font-size: 14px;">Best Practices</p> <ul> <li>Keep disk utilization below 75% to ensure continuous data capture</li> <li>Use lowercase letters and underscores for column names in baseline datasets</li> <li>Leverage StartTimeOffset and EndTimeOffset for Ground Truth integration</li> </ul> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Setup Method</strong></td> <td style="border: 1px solid #ddd; padding: 8px;"><strong>Description</strong></td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">SageMaker Python SDK</td> <td style="border: 1px solid #ddd; padding: 8px;">Uses Model Monitor module for baselines and schedules</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Pipelines</td> <td style="border: 1px solid #ddd; padding: 8px;">Integrates through QualityCheck and ClarifyCheckStep APIs</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">SageMaker Studio Classic</td> <td style="border: 1px solid #ddd; padding: 8px;">Create schedules directly from the UI</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 8px;">Model Dashboard</td> <td style="border: 1px solid #ddd; padding: 8px;">Enable monitoring on endpoints from the console</td> </tr> </table> <p>These FAQs provide a comprehensive overview of SageMaker Model Monitor's capabilities, customization options, and best practices for effective model monitoring in production environments.</p> </div>

		<div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;"> <table style="border-collapse: collapse; width: 100%;"> <tr style="background-color: #f2f2f2;"> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Monitoring Dimension</th> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Definition</th> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Data Quality</strong></td> <td style="border: 1px solid #ddd; padding: 12px;">Monitors the statistical properties of the input data to detect changes or anomalies that could affect model performance. This includes checking for missing values, data type mismatches, or shifts in feature distributions.</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Model Quality</strong></td> <td style="border: 1px solid #ddd; padding: 12px;">Assesses the performance of the model over time by comparing predictions to ground truth labels. This helps detect degradation in model accuracy, precision, recall, or other relevant metrics.</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Bias Drift</strong></td> <td style="border: 1px solid #ddd; padding: 12px;">Tracks changes in model fairness by monitoring how predictions vary across different subgroups or protected attributes. This helps identify if the model is developing or increasing bias against certain populations over time.</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Feature Attribution Drift</strong></td> <td style="border: 1px solid #ddd; padding: 12px;">Monitors changes in the importance or impact of different features on the model's predictions. This helps detect shifts in the model's decision-making process, which could indicate concept drift or changes in the underlying data relationships.</td> </tr> </table> </div>


		<div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;"> <p style="color: #333; font-size: 16px; font-weight: bold;">Data Quality Monitoring</p> <table style="border-collapse: collapse; width: 100%; margin-bottom: 20px;"> <tr style="background-color: #f2f2f2;"> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Aspect</th> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Description</th> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>SageMaker Feature</strong></td> <td style="border: 1px solid #ddd; padding: 12px;">Model Monitor - Data Quality</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>How it Helps</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Detects changes in statistical properties of input data</li> <li>Identifies missing values, data type mismatches, or distribution shifts</li> <li>Helps maintain data integrity and prevent model degradation due to data issues</li> </ul> </td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Key Components</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Baseline statistics and constraints</li> <li>Data Capture for real-time or batch transform jobs</li> <li>Monitoring schedules for regular checks</li> </ul> </td> </tr> </table> <p style="color: #333; font-size: 16px; font-weight: bold;">Model Quality Monitoring</p> <table style="border-collapse: collapse; width: 100%; margin-bottom: 20px;"> <tr style="background-color: #f2f2f2;"> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Aspect</th> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Description</th> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>SageMaker Feature</strong></td> <td style="border: 1px solid #ddd; padding: 12px;">Model Monitor - Model Quality</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>How it Helps</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Assesses model performance over time</li> <li>Compares predictions to ground truth labels</li> <li>Detects degradation in model accuracy, precision, recall, or other metrics</li> </ul> </td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Key Components</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Ground Truth integration</li> <li>Performance metric baselines</li> <li>Monitoring schedules with specified time offsets for Ground Truth data</li> </ul> </td> </tr> </table> <p style="color: #333; font-size: 16px; font-weight: bold;">Bias Drift Monitoring</p> <table style="border-collapse: collapse; width: 100%; margin-bottom: 20px;"> <tr style="background-color: #f2f2f2;"> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Aspect</th> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Description</th> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>SageMaker Feature</strong></td> <td style="border: 1px solid #ddd; padding: 12px;">SageMaker Clarify - Bias Monitoring</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>How it Helps</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Tracks changes in model fairness across different subgroups</li> <li>Identifies if the model is developing or increasing bias over time</li> <li>Helps maintain ethical and fair AI practices</li> </ul> </td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Key Components</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Bias metrics (e.g., DPPL - Difference in Positive Proportions in Labels)</li> <li>Baseline bias constraints</li> <li>Monitoring schedules with bias checks</li> </ul> </td> </tr> </table> <p style="color: #333; font-size: 16px; font-weight: bold;">Feature Attribution Drift Monitoring</p> <table style="border-collapse: collapse; width: 100%; margin-bottom: 20px;"> <tr style="background-color: #f2f2f2;"> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Aspect</th> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Description</th> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>SageMaker Feature</strong></td> <td style="border: 1px solid #ddd; padding: 12px;">SageMaker Clarify - Explainability Monitoring</td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>How it Helps</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Monitors changes in feature importance for model predictions</li> <li>Detects shifts in the model's decision-making process</li> <li>Identifies potential concept drift or changes in data relationships</li> </ul> </td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Key Components</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>SHAP (SHapley Additive exPlanations) values</li> <li>Baseline feature attribution</li> <li>NDCG (Normalized Discounted Cumulative Gain) score for comparing rankings</li> <li>Monitoring schedules with explainability checks</li> </ul> </td> </tr> </table> </div>

		<div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;"> <p style="color: #333; font-size: 16px; font-weight: bold;">Comprehensive Summary: Amazon SageMaker Model Monitoring</p> <p>Amazon SageMaker provides a robust suite of tools for comprehensive model monitoring, addressing four key dimensions: Data Quality, Model Quality, Bias Drift, and Feature Attribution Drift. These monitoring capabilities help ensure the ongoing performance, fairness, and reliability of machine learning models in production.</p> <table style="border-collapse: collapse; width: 100%; margin-bottom: 20px;"> <tr style="background-color: #f2f2f2;"> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Monitoring Dimension</th> <th style="border: 1px solid #ddd; padding: 12px; text-align: left;">Key Features and Benefits</th> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Data Quality</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Detects statistical changes in input data</li> <li>Identifies data integrity issues (missing values, type mismatches)</li> <li>Uses Model Monitor with baseline statistics and constraints</li> <li>Supports both real-time endpoints and batch transform jobs</li> </ul> </td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Model Quality</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Assesses model performance over time</li> <li>Compares predictions to ground truth labels</li> <li>Integrates with Amazon SageMaker Ground Truth</li> <li>Uses time offsets to align predictions with delayed ground truth data</li> </ul> </td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Bias Drift</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Monitors fairness across different subgroups</li> <li>Uses SageMaker Clarify for bias detection</li> <li>Employs metrics like DPPL (Difference in Positive Proportions in Labels)</li> <li>Helps maintain ethical AI practices</li> </ul> </td> </tr> <tr> <td style="border: 1px solid #ddd; padding: 12px;"><strong>Feature Attribution Drift</strong></td> <td style="border: 1px solid #ddd; padding: 12px;"> <ul> <li>Tracks changes in feature importance</li> <li>Uses SHAP (SHapley Additive exPlanations) values</li> <li>Employs NDCG score to compare feature rankings</li> <li>Detects shifts in model decision-making processes</li> </ul> </td> </tr> </table> <p style="color: #0066cc; font-size: 14px;">Key Components and Functionalities:</p> <ul> <li><strong>Data Capture:</strong> Automatically logs model inputs and outputs to Amazon S3</li> <li><strong>Baseline Creation:</strong> Establishes reference points for comparison in all monitoring dimensions</li> <li><strong>Monitoring Schedules:</strong> Allows regular, automated checks for drift and anomalies</li> <li><strong>Pre-built Containers:</strong> Provides ready-to-use analysis tools for tabular data</li> <li><strong>Custom Containers:</strong> Supports bring-your-own-container for specialized monitoring needs</li> <li><strong>Integration with SageMaker Studio and Model Dashboard:</strong> Offers visual interfaces for monitoring and analysis</li> </ul> <p style="color: #0066cc; font-size: 14px;">Advanced Features:</p> <ul> <li><strong>Customization:</strong> Supports pre-processing and post-processing scripts for tailored analysis</li> <li><strong>Flexibility:</strong> Allows on-demand monitoring jobs through SageMaker Processing</li> <li><strong>Comprehensive Metrics:</strong> Publishes a wide range of metrics to Amazon CloudWatch</li> <li><strong>Violation Reporting:</strong> Generates detailed reports on constraint violations</li> </ul> <p style="color: #0066cc; font-size: 14px;">Best Practices:</p> <ul> <li>Regularly update baselines to adapt to evolving data patterns</li> <li>Use appropriate time offsets when working with delayed ground truth data</li> <li>Leverage both automated monitoring and manual review of reports for comprehensive oversight</li> <li>Customize monitoring thresholds based on domain knowledge and business requirements</li> <li>Integrate monitoring into the broader MLOps workflow for seamless model lifecycle management</li> </ul> <p>By leveraging these monitoring capabilities, organizations can maintain high-quality, fair, and reliable machine learning models in production, ensuring ongoing value delivery and minimizing risks associated with model drift and degradation.</p> </div>

		
		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Services</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            
		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Services</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            
		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Services</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            
		</div>
	</div>
	
	<br/>
	
</div>


<div class="container mt-5">
	<h3 class="text-primary h4">Services</h3>
	<!--<p class="lh-1" style="color:#BC8E19;">Software Developer | Cloud Architect</p>-->
	<p></p>
	<div class="row">
		<div class="col-sm-12">
            
            
		</div>
	</div>
	
	<br/>
	
</div>





<br/>
<br/>
<footer class="_fixed-bottom">
<div class="container-fluid p-2 bg-primary text-white text-center">
  <h6>christoferson.github.io 2023</h6>
  <!--<div style="font-size:8px;text-decoration:italic;">about</div>-->
</div>
</footer>

</body>
</html>
