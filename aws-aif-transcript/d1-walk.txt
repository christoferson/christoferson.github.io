

Welcome to our first walkthrough question for the course. These walkthroughs are meant to assist you in a few ways. First, this will be an opportunity to see the types of questions that you'll encounter on the actual exam. Although the questions aren't pulled directly from the Certification exam, they are of similar quality and difficulty and will give you exposure to this style of questioning. Second, I wanna show you methods I consider to be helpful when you're working with multiple-choice questions. These methods help you focus on what you're looking for and help you identify distractors and incorrect answers you might encounter on the exam. And third, these questions will provide you with additional information. Any questions you feel confident in will reinforce your knowledge in that area, and any questions that reveal gaps in your knowledge will help you identify where to focus in your studies going forward. As I go through each of the questions, I'll generally follow a particular format. I'll start by reading through the question. Then I'll identify keywords and phrases in the question that indicate what you're looking for in the answers. After that, I'll go through the questions and give you time to figure out if you can identify the correct answer yourself. After you've been given a chance to figure it out yourself, I'll go through the answers and discuss why they're correct or incorrect. The first couple of questions are part of a case study. Each case study in the course and on the Certification exam will consist of two or more questions. Let's first read the case study's main scenario. A company wants to gain insights from diverse data sources and formats to improve business operations. The data sources include audio from call centers, text feedback from customers, product images, and scanned documents. The first question in this case study labeled question 1 of 2 is from task statement 1.2: Identify practical use cases for AI. The question reads: The company wants to accurately identify historic audio files that contain the company's brand and convert the files to text for further analysis. The historic audio files are stored in Amazon S3. Which combination of steps will meet these requirements? Select two. Reading this question, can you identify any keywords or phrases? Also, what exactly is the question asking? A few keywords I identified are to identify audio files, convert the files to text, and the files are stored in Amazon S3. You need to select two answer options and choose the steps for the requirements. And keywords for the case study, main scenario are gained insights from diverse data sources and formats. Part of the data sources from the case study include audio files from call centers. Now that we have examined the stem, identified keywords and reviewed the requirements, let's explore the responses. Option A, create a batch transcription job in Amazon Transcribe. Option B, create a real-time transcription job in Amazon Transcribe. Option C, create a transcription job in Amazon Translate. Option D, use custom vocabularies to improve the transcription accuracy. Option E, use custom language models to improve the transcription accuracy. Pause the video if you need more time. Okay, let's evaluate the options. Option A is a possible correct answer. Amazon Transcribe is a service that you can use to convert speech into text. You can use Amazon Transcribe to facilitate the transcription of audio recordings. Amazon Transcribe has two types of transcription jobs, batch and streaming. Batch jobs work with data, historic, that has been previously uploaded to Amazon S3. Streaming jobs transcribe media in real time, and because the data consists of historic audio files that are stored in Amazon S3, you must use a batch transcription job. But even though this is a possible correct answer, it is best practice to first review all of the answer options and then choose your best answer. Option B is incorrect. Because the data consists of historic audio files that are stored in Amazon S3, you must use a batch transcription job. You cannot use real-time transcription for historic data that is stored in Amazon S3. Option C is also incorrect. Amazon Translate is a service that you can use to provide translations between multiple languages. You cannot use Amazon Translate to convert audio speech to text. Option D is another possible correct answer. In Amazon Transcribe, if media contains domain-specific or non-standard terms, you can use a custom vocabulary or a custom model to improve the accuracy of the transcriptions. Examples of domain-specific and non-standard terms include brand names, acronyms, technical words, and jargon. In the case of a limited number of words, a custom vocabulary is recommended. To identify the company's brand name would require a limited number of words. Therefore, you can use this step to improve the transcription accuracy. But even though this is a possible correct answer, it is best practice to first review all of the answer options and then choose your best choice answer. Let's review the last answer option. Option E is incorrect. We already discussed how Amazon Transcribe can be used to have a custom vocabulary or a custom model to improve the accuracy of the transcriptions. We also covered what domain-specific terms can include. To identify the company's brand name would require a limited number of words. You would use a custom model if the domain is too complex or if you must provide a complex taxonomy because the domain is very specific. The company wants to accurately identify historic audio files that contain the company's brand. Therefore, you do not need a custom language model in this scenario. So that makes options A and D correct. That's all for this question. Be sure to take note of any knowledge gaps that you may have identified while exploring this question. Let's get started with our second question in this case study. 


Let's get started with our second question in this case study, and let's begin by reviewing the main scenario again. Remember, the main scenario repeats in each question in the case study. A company wants to gain insights from diverse data sources and formats to improve business operations. The data sources include audio from call centers, text feedback from customers, product images, and scanned documents. Now let's review the second question in this case study. The second case study question, two of two, is also from task statement 1.2, identify practical use cases for AI. The question reads, "Which AWS service can identify the global sentiment of customer feedback from text?" Reading this question, can you identify any keywords or phrases? Also, what exactly is the question asking? A few keywords I identified are identify, global sentiment, and text. Also, you need to choose the service that can help you identify the global sentiment of customer feedback from text. And keywords for the case study main scenario are gain insights from diverse data sources and formats. Part of the data sources from the case study include text feedback from customers. Now that we have examined the question and identified keywords, let's explore the responses. Option A, Amazon Translate, option B, Amazon Comprehend, option C, Amazon Transcribe, and option D, Amazon Polly. Pause the video if you need more time. Okay, let's evaluate the options. Option A is incorrect. Amazon Translate is a service that provides translation between multiple languages. You cannot use Amazon Translate to identify sentiment from text. Option B is a possible correct answer. Amazon Comprehend is a natural language processing, or NLP, service that extracts insights and relationships from text data by using ML. You can use Amazon Comprehend to understand the sentiment of customer feedback and text. Even though this is a possible correct answer, it is a best practice to first review all the answer options and then choose your best choice answer. Option C is incorrect. Amazon Transcribe is a service that you can use to convert speech into text. Amazon Transcribe can facilitate the transcription of audio recordings. However, you cannot use Amazon Transcribe to identify the sentiment of customer feedback, and option D is incorrect. Amazon Polly is a text-to-speech service that you can use to convert text into lifelike speech. You cannot use Amazon Polly to identify the sentiment of customer feedback. So that makes option B the correct answer. That's all for this question and this case study. Be sure to take note of any knowledge gaps that you may have identified while exploring this case study. Let's get started with the next walkthrough question. 


Let's get started with the second walkthrough question from task statement 1.3. Describe the ML development lifecycle. There are dropdown lists in the answer area, so that tells me this is an ordering or matching question. The question reads, A data scientist is building an ML model. Select the correct ML development stage from the following list for each ML development step. Each ML development stage should be selected one time. Select four. The stages are feature engineering, model deployment, model evaluation, and model monitoring. Reading this question, can you identify any keywords or phrases? Also, what exactly is the question asking? A few keywords identified are select, which makes this a matching item. If it were an ordering item, it would say "select and order" instead. You need to identify what you, the learner, is matching, which is ML development stage to each development step. Now that we have examined the question and identified keywords, let's explore the prompts and match for the ML development steps. Because the question is a matching question, you need to match each ML development stage to the response that describes what you do in that stage. The prompts read, perform explainability techniques to identify the accuracy of model-generated results. Identify data quality issues, model quality issues, bias drift, or feature attribution drift. Release the model into production so the model can begin making predictions. Select and transform variables to enhance a training dataset. Think through your answers and pause the video if you need more time. Again, the first prompt is perform explainability techniques to identify the accuracy of model-generated results. This matches to the model evaluation stage. Model evaluation is a stage in the ML development lifecycle that typically occurs after model training. During model evaluation, you perform explainability techniques and evaluate the accuracy and performance of the model. The goal of model evaluation is to determine if the model requires additional data fine-tuning, ML algorithm fine-tuning, or if the model is ready for deployment. The second prompt is identify data quality issues, model quality issues, bias drift, or feature attribution drift, and this option matches to model monitoring. Model monitoring is a stage in the ML development lifecycle that occurs after model deployment. During model monitoring, you monitor the model to identify issues that relate to data or model quality, and issues that relate to bias or feature attribution drift. The goal of model monitoring is to identify if the model maintains the necessary performance levels and identify when there is drift or model degradation. The third prompt is release the model into production so the model can begin making predictions. This option matches to model deployment. Model deployment is a stage in the ML development lifecycle that occurs after a model is trained, tuned, and evaluated. During model deployment, you deploy the model into production to begin making predictions. The fourth prompt is select and transform variables to enhance a training dataset. This option matches to feature engineering. Feature engineering, which is a step in the ML development lifecycle that occurs during the data preparation stage. During feature engineering, you select and transform variables to create features or attributes. Feature engineering creates features or variables that can help the model generate more accurate results and improve overall performance during model training. Let's check and see if we match the correct functionality to the AWS service. That's all for this question. Be sure to take note of any knowledge gaps that you might have identified while exploring this question. Now is your chance to practice and dive deeper on Domain 1 topics before continuing to Domain 2. If you are taking the enhanced course, you'll move on to bonus questions, flashcards, and a lab. Whether you're taking the standard or enhanced course, you'll see a list of additional resources to learn more about the topics covered. 