Let's get started with the first task statement from Domain 1, which is to explain basic AI concepts and terminologies. This task statement is split into five lessons. Let's get started by describing what artificial intelligence is. We'll also give some examples. Artificial intelligence, AI, is the field of computer science dedicated to solving cognitive problems commonly associated with human intelligence, such as learning, creation, and image recognition. The goal with AI is to create self-learning system that derives meaning from data. As you likely have already experienced Alexa and ChatGPT, AI technology can respond meaningfully when you ask it questions. It can even create original content such as text and images. Because AI systems can quickly process vast quantities of data, they can be used to solve complex problems like real-time fraud detection. AI also can perform repetitive and monotonous tasks, which increases business efficiency by freeing up employees to do more creative work. AI is exceptionally powerful when it comes to finding patterns in data and forecasting trends. This helps businesses make smarter decisions and react more quickly to problems. Machine learning is a branch of AI and computer science that focuses on use of data and algorithms to imitate the way humans learn. It gradually improves its accuracy to build computer systems that learn from data. Machine learning models are trained by using large datasets to identify patterns and make predictions. An example would be a product recommendation for a customer who's shopping online. Deep learning is a type of machine learning model that is inspired by human brains using layers of neural networks to process information. Recognizing human speech and objects and images are some of the things that deep learning models can do. AI systems provide benefits to many industries and their customers. AI systems are used in the medical industry to help read X-rays and scans and make diagnosis. Agencies such as the Center for Disease Control, CDC, Use AI to predict pandemics and outbreaks across the globe and send needed medical personnel and resources. Manufacturers such as Koch Industries use AI with computer vision to monitor assembly lines and maintain product quality. They also monitor sensor data to predict when equipment needs maintenance before it fails. Customers have easier access to product and support information with chat and search systems that can recognize their language and direct them to solutions. AI systems use shopping activity history to make product recommendations and help customers buy the things they want. Discovery uses AI to make personalized content recommendations for their viewers based upon their viewing history. Businesses can be more efficient and better serve their customers by being able to more accurately forecast demand. For example, a taxi company uses AI to position their cars in locations and at times when customers are likely to need them. Financial institutions such as MasterCard can detect fraudulent transactions by using AI to detect anomalous activity. HR departments can use AI to process resumes and match candidates to open roles and help hiring managers to be more productive. Companies use the understanding of their customers that AI gives them to target the customers with promotions that they will most likely want and avoid spamming. TickeTek uses AI to send, show, and event recommendations to their customers tailored to their unique interests. Using a technique called regression analysis, an AI model can process historical data, also known as time series data and predict future values. For example, a store needs to know how many salespeople it might need on a given day to serve its customers. An AI model can analyze the patterns in the past and forecast how many customers will be in the store on a given day in the future. Predictions that AI makes are called inferences. Note that an inference is basically an educated guess, so the model gives a probabilistic result. Because AI can recognize patterns in data, it can also detect when there is a deviation from the expected pattern known as an anomaly. In this example, the number of calls a customer service team receives might vary throughout the day in a predictable manner. When something happens, like the call center application goes offline, AI can detect the drop in calls and notify the IT department. Computer vision applications use AI to process images and video for object identification and facial recognition, as well as classification, recommendation, monitoring, and detection. In this example, a computer vision model detected scratches on a surface and put a red box around them on the image. In a more advanced application, the model identified that there is a missing capacitor on a circuit board. AI can translate text from one language to another without human involvement. It goes beyond simple word-to-word translation. It analyzes all text elements and recognizes how the words influence one another to be able to communicate the meaning of the phrase accurately in the target language. Here is an example of a customer support chat application. The customer is typing in Spanish while the support rep is typing in English. The application is translating between English and Spanish in real time. Natural language processing, NLP, is what allows machines to understand, interpret, and generate human language in a natural-sounding way. This is the technology that powers Alexa devices and those chatbots that let you book a hotel. In this example, the chatbot is prompting the customer to supply the information that it needs to make the reservation. Generative AI is the next step in artificial intelligence. Generative AI can have seemingly intelligent conversations and generate original content like stories, images, videos, and even music. Here is an example that uses Amazon Bedrock. When you use generative AI, you typically start with a prompt. My prompt is generate a song from these lyrics. In order to pass the exam, you'll need to know AI. And here is the response. Wow, not bad. From my single prompt, I received complete song lyrics with two verses, a chorus, bridge, and outro, and it mostly rhymes. I'm going to pause this lesson here, and in the next lesson, we will continue talking about task statement 1.1. 

Let's continue with task statement 1.1, which is to explain basic AI concepts and terminologies. And let's concentrate on a specific type of artificial intelligence, machine learning. Machine learning is the science of developing algorithms and statistical models that computer systems use to perform complex tasks without explicit instructions. Computer systems use ML algorithms to process large quantities of historical data, and identify data patterns. Machine learning starts with a mathematical algorithm that takes data as inputs, and generates an output. To train the algorithm to produce the output we expect, we give it known data, which consists of features. You can think of features as the columns in a table, or the pixels in an image. We continue to train the algorithm by giving it more known data to analyze. Its task is to find the correlation between the input data features and the known expected output, if available. Adjustments are made to the model by changing internal parameter values until the model reliably produces the expected output. A trained model is then able to make accurate predictions and produce output from new data that it hasn't seen during training. This is known as inference. ML models can be trained on different types of data from various sources. One type of data is structured data, which is the easiest to understand and to process. This type of data is stored as rows in a table with columns, which can serve as the features for an ML model. As an example, structured data can be text files like CSV, or stored in relational databases like Amazon Relational Database Service, Amazon RDS, or Amazon Redshift. It can be queried using structured query language, or SQL for short. For model training, it would be exported into Amazon Simple Storage Service, or Amazon S3. Amazon S3 is the primary source for training data because it can store any type of data, is lower cost, and has virtually unlimited storage capacity. Another type of data is semi-structured. Semi-structured data doesn't completely follow the rules of structured tabular data. Unlike data in a table, semi-structured data elements can have different attributes or missing attributes. An example of semi-structured data is a text file that contains JSON, which stands for JavaScript Object Notation. In a document like this, the features are represented as key-value pairs. Amazon DynamoDB and Amazon DocumentDB with MongoDB compatibility, are two examples of transactional databases built specifically for semi-structured data. For training ML models, that data would be exported into Amazon S3. Unstructured data is data that doesn't conform to any specific data model and can't be stored in table format. Some examples include images, video, and text files, or social media posts. Unstructured data is typically stored as objects in an object storage system like Amazon S3. The features for machine learning are derived from the objects by using processing techniques like tokenization, which breaks down text into individual units of words or phrases. Time series data is important for training models that need to predict future trends. Each data record is labeled with a timestamp, and stored sequentially. This example shows the performance metrics for microservice, including the used memory, CPU percentage, and transactions per second. A machine learning model could discover the patterns in this data. It could then use it to proactively scale out the infrastructure for the service before load is expected to increase. Depending on the sampling rate, time series data captured for long periods can get quite large and be stored in Amazon S3 for model training. To create a machine learning model, we need to start with an algorithm which defines the mathematical relationship between outputs and inputs. In this simple example of linear regression, we want to find the best fit for a line to match the input data. In this case, we have the height and weight of several people to use for our training data. The simple linear equation y=mx+b, or in this case, h=mw+b, defines the linear relationship between our independent variable, w, and the dependent variable, h. The slope, m, and intercept, b, are the model parameters that are adjusted iteratively during the training process to find the best-fitting model. To determine the best fit, we look for the parameter values that minimize the errors. In this case, the errors are distances between the data points and the line. When the model training is complete, it's ready to begin making inferences. For this example, our model will infer the person's height from their weight. I'm going to pause this lesson here, and in the next lesson, we will continue talking about task statement 1.1. 

Let's continue with task statement 1.1, which is to explain basic AI concepts and terminologies. We ended the last lesson with model training. The training process produces model artifacts, which typically consists of trained parameters, a model definition that describes how to compute inferences and other metadata. The model artifacts, which are normally stored in Amazon S3, are packaged together with inference code to make a deployable model. Inference code is the software that implements the model, by reading the artifacts. There are two general options for hosting a model. The first is where an endpoint is always available to accept inference requests in real time. And the second is where a batch job is performing inference. Real-time inference is ideal for online inferences that have low latency and high throughput requirements. For real-time inferencing, your model is deployed on a persistent endpoint to handle a sustained flow of requests. Clients send input data to the model and receive back and inference very quickly. Another option is batch. Batch is suitable for offline processing when large amounts of data are available upfront, and you don't need a persistent endpoint. When you need a large number of inferences, and it's okay to wait for the results, batch processing can be more cost-effective. For example, you have historical sales data and you want to forecast the needed inventory for the next month for each product in your catalog. Your model input data could be processed all at once on a monthly schedule, and the results could be used to generate a report. The main difference between real-time and batch is that with batch, the computing resources only run when processing the batch, and then they shut down. With real-time inferencing, some compute resources are always running and available to process requests. There are several distinct machine learning styles that can be used depending on the expected output and the input type. The first is supervised learning. With supervised learning, you train your model with data that is pre-labeled. In this example, we show the model pictures of fish, and these are labeled as fish. In the same dataset, we include pictures of other animals like manatees, and these are labeled as not fish. So our training data specifies both, the input and the desired output of the algorithm. For an image classification problem like this, the model will be looking at the pixels of the image and recognizing clusters and patterns. The internal parameters of the algorithm are adjusted during the training process. It continues until the model is successfully identifying as fish, the images that are labeled as fish, and identifying others as non-fish. Note that machine learning inferences are not always accurate, so what the model will actually generate is the probability that an image is of a fish. The challenge with supervised learning is in labeling the data. The model might need to be trained on many thousands of pictures of fish before it makes reliable predictions. This involves people who must look at an image and label it. To address this challenge, Amazon offers a labeling service, Amazon SageMaker Ground Truth. SageMaker Ground Truth can leverage crowdsourcing service called Amazon Mechanical Turk that provides access to a large pool of affordable labor spread across the globe. Unsupervised learning algorithms train on data that has features but is not labeled. They can spot patterns, group the data into clusters, and split the data into a certain number of groups. Unsupervised learning is useful for use cases such as pattern recognition, anomaly detection, and automatically grouping data into categories. As the training data does not require labeling, setup is straightforward. These algorithms can also be used to clean and process data for further modeling automatically. An example of clustering is identifying different types of network traffic to predict potential security incidents. Because unsupervised learning can detect abnormalities, it is commonly used for anomaly detection. For example, an ML model examines data collected from sensors. It can detect that a temperature sensor at an oil well might be failing if it's reported data is well outside of the normal range. Reinforcement learning is a machine learning method that is focused on autonomous decision making by an agent. The agent takes actions within an environment to achieve specific goals. The model learns through trial and error, and training does not require labeled input. Actions that an agent takes that move it closer to achieving the goal are rewarded. To encourage learning during training, the learning agent must be allowed to sometimes pursue actions that might not result in rewards. To teach developers about developing a reinforcement learning model, Amazon offers a model race car called AWS DeepRacer that you can teach to drive on a racetrack. With AWS DeepRacer, the car is the agent, and the track is the environment. An action is the car moving forward on the track, and the goal is to stay on the track and finish the course as efficiently as possible. Both unsupervised and reinforcement learning work without labeled data. Unsupervised learning algorithms receive inputs with no specified outputs during the training process. However, reinforcement learning has a predetermined end goal. While it takes an exploratory approach, the explorations are continuously validated and improved to increase the probability of reaching the end goal. I'm going to pause this lesson here, and in the next lesson, we will continue talking about task statement 1.1. 

Let's continue with task statement 1.1, which is to explain basic AI concepts and terminologies. As we've seen, the output of a machine learning model is an inference. In our fish example, we trained our model to recognize images of fish by training it with images of fish swimming in the water. However, our deployed model might see images of fish that are a bit different, like a fish out of water, and not recognize them as fish. When a model performs better on training data than it does on new data, it is called overfitting, and it is said that the model does not recognize well. The model fits the training data too well, so when it sees something slightly different, it thinks the probability is low that it is a fish. Usually, the best way to correct a model that is overfitting is to train it with data that is more diverse. Sometimes, if you train your model for too long, it will start to overemphasize unimportant features called noise, which is another way of overfitting. Underfitting is a type of error that occurs when the model cannot determine a meaningful relationship between the input and output data. Underfit models give inaccurate results for both the training dataset and new data. This can happen if you haven't trained the model long enough or with a large enough dataset. Because training for too long can cause overfitting, data scientists try to find the sweet spot for training time where the model doesn't underfit or overfit. Bias is when there are disparities in the performance of a model across different groups. The results are skewed in favor of or against an outcome for a particular class. As an example, consider a machine learning model for automatically improving loan applications. The training data, we have examples of loan applications that should be approved and those that should not. If the training data doesn't have enough applications from diverse population, the model could learn a pattern that is biased against a particular group. For example, the loan application contains features like the customer's income, job history, age, gender, and location. Suppose that there aren't any approved applications from 25-year-old women living in Wisconsin in the training data. Then, the model could learn that those should not be approved, even though other features such as their income and job history would qualify them. The quality of a model depends on the underlying data quality and quantity. Also, if a model is showing bias, the weight of features that are introducing noise can be directly adjusted by the data scientists. For example, it could completely remove gender consideration by the model. Fairness constraints, such as age and sex discrimination, should be identified at the beginning before creating a model. Training data should be inspected and evaluated for potential bias, and models need to be continually evaluated by checking their results for fairness. I'm going to pause this lesson here. And in the next lesson, we will continue talking about task statement 1.1. 

Let's continue with task statement 1.1, which is to explain basic AI concepts and terminologies. And let's concentrate on a specific type of machine learning, deep learning. Deep learning is a type of machine learning that uses algorithmic structures called neural networks. These are based upon the structure of the human brain. In our brains, brain cells called neurons form a complex network where they send electrical signals to each other to help us process information. In deep learning models, we use software modules called nodes to simulate the behavior of neurons. Deep neural networks comprise layers of nodes, including an input layer, several hidden layers, and an output layer of nodes. Every node in the neural network autonomously assigns weights to each feature. Information flows through the network in a forward direction from input to output. During training, the difference between the predicted output and the actual output is then calculated. The weights of the neurons are repeatedly adjusted to minimize the error. Deep learning can excel at tasks like image classification and natural language processing where there is a need to identify the complex relationship between data objects. In our fish example from earlier, we saw that we can train a machine model to recognize objects in an image, but training the model required a lot of human effort to label thousands of images. This is the way that image classification, object detection, and other forms of computer vision have traditionally operated in the past. The concept of deep learning with neural networks has existed for some time. However, the required computing power wasn't visible for most businesses to obtain until the arrival of low-cost cloud computing. Because anyone can now readily use powerful computing resources in the cloud, neural networks have become the standard algorithmic approach to computer vision. A big advantage of deep learning models for computer vision is that they don't need the relevant features given to them. They can identify patterns in images and extract the important features on their own. However, we might need to give a deep learning model millions of pictures of fish before it can accurately detect and label a fish in an image. And the compute infrastructure to train a deep learning model repeatedly on such a large dataset is going to cost more than the traditional approach. The decision to use traditional machine learning or deep learning depends on the type of data you need to process. Traditional machine learning algorithms will generally perform well and be efficient when it comes to identifying patterns from structured data and labeled data. Examples include classification and recommendation systems. For instance, a cell phone company can use ML to predict when a customer will change carriers based on previous customer churn data. On the other hand, deep learning solutions are more suitable for unstructured data like images, videos, and text. Tasks for deep learning include image classification and natural language processing, where the is a need to identify the complex relationships between pixels and words. For example, a deep learning solution can analyze social media mentions or product feedback to determine user sentiment. Both types of machine learning use statistical algorithms, but only deep learning uses neural networks to simulate human intelligence. As we've seen, deep learning models self-learn patterns, so they don't require as much work on selecting and extracting features. However, their infrastructure costs are significantly higher. Finally, let's finish this lesson by talking more about generative AI. Generative AI is accomplished by using deep learning models that are pre-trained on extremely large datasets containing strings of text or, in AI terms, sequences. They use transformer neural networks, which change an input sequence, in Gen AI known as prompt, into an output sequence, which is the response to your prompt. Neural networks process the elements of a sequence sequentially one word at a time. Transformers process the sequence in parallel, which speeds up the training and allows much bigger datasets to be used. Large language models contain many billions of features, which captures a wide range of human knowledge. With all this training, large models are very flexible in the tasks they can perform. They outperform other ML approaches to natural language processing. They excel at understanding human language so they can read long articles and summarize them. They are also great at generating text that's similar to the way a human would. As a result, they are good at language translation and even writing original stories, letters, articles, and poetry. They even know computer programming languages and can write code for software developers. Here, I asked Amazon Bedrock to explain large language models. If you want to try Amazon Bedrock for yourself for free, you can build your own AI app at partyrock.aws. All right, let's get started with task statement 1.2 in the next lesson. 

